{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/fastai/fastai\n",
    "# !pip install git+https://github.com/fastai/fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip install light-the-torch \n",
    "# #>> /.tmp\n",
    "# !ltt install torch torchvision\n",
    "# # >> /.tmp\n",
    "!pip install -U fastai\n",
    "!pip install -U fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import __version__ as fastai_version\n",
    "fastai_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.gan import *\n",
    "from functools import partial\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.nn.utils.spectral_norm import SpectralNorm\n",
    "from torchvision.models.vgg import vgg19\n",
    "from typing import Callable, List, Tuple, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "img_size = 64\n",
    "n_channels = 3\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "animecharacterfaces, by Kaggle user *aadilmalik94*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anime_faces_path = Path('/kaggle/input/animecharacterfaces/animeface-character-dataset/data').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celeba_path = Path('./img_align_celeba')\n",
    "celeba_path = Path('/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba')\n",
    "#target_fns = get_image_files(celeba_path)\n",
    "# get_image_files is too slow, there's no need to check the extension here\n",
    "target_fns = celeba_path.ls()\n",
    "target_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_tf = Normalize.from_stats(torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5]))\n",
    "normalize_imagenet_tf = Normalize.from_stats(*imagenet_stats)\n",
    "\n",
    "dblock = DataBlock(blocks=(TransformBlock, ImageBlock),\n",
    "                   get_x=generate_noise,\n",
    "                   #get_items=get_image_files,\n",
    "                   get_items=lambda path: target_fns,\n",
    "                   splitter=IndexSplitter([]),\n",
    "                   item_tfms=Resize(img_size, method=ResizeMethod.Crop), \n",
    "                   batch_tfms=normalize_tf)\n",
    "#main_path = anime_faces_path\n",
    "main_path = celeba_path\n",
    "dls = dblock.dataloaders(main_path, path=main_path, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANGPCallback(Callback):\n",
    "    def __init__(self, plambda=10., epsilon_sampler=None, center_val=1): \n",
    "        self.plambda = plambda\n",
    "        if epsilon_sampler is None: epsilon_sampler = random_epsilon_gp_sampler\n",
    "        self.epsilon_sampler = epsilon_sampler\n",
    "        self.center_val = center_val\n",
    "        \n",
    "    def _gradient_penalty(self, real, fake, plambda, epsilon_sampler):\n",
    "        epsilon = epsilon_sampler(real, fake)\n",
    "        x_hat = (epsilon * real + (1 - epsilon) * fake).requires_grad_(True)\n",
    "        x_hat_pred = self.model.critic(x_hat).mean()\n",
    "\n",
    "        grads = torch.autograd.grad(outputs=x_hat_pred, inputs=x_hat, create_graph=True)[0]\n",
    "        return plambda * ((grads.norm() - self.center_val)**2)    \n",
    "        \n",
    "    def after_loss(self):\n",
    "        if not self.gan_trainer.gen_mode:\n",
    "            # In critic mode, GANTrainer swaps x and y; so, here x is original y (real target)\n",
    "            real = self.x\n",
    "            assert not self.y.requires_grad\n",
    "            # Cast to TensorImage to enable product compatibility\n",
    "            fake = TensorImage(self.model.generator(self.y))\n",
    "            # Updated to fastai version 2.2.7: backward isn't called on learn.loss anymore, \n",
    "            # but on learn.loss_grad\n",
    "            self.learn.loss_grad += self._gradient_penalty(real, fake, self.plambda, self.epsilon_sampler)\n",
    "\n",
    "\n",
    "def random_epsilon_gp_sampler(real: torch.Tensor, fake: torch.Tensor) -> torch.Tensor:\n",
    "    # A different random value of epsilon for any element of a batch\n",
    "    epsilon_vec = torch.rand(real.shape[0], 1, 1, 1, dtype=torch.float, device=real.device, requires_grad=False)\n",
    "    return epsilon_vec.expand_as(real)\n",
    "\n",
    "            \n",
    "class R1GANGPCallback(Callback):\n",
    "    def __init__(self, weight=10.): \n",
    "        self.weight = weight\n",
    "        \n",
    "    def _gradient_penalty(self, real, weight):\n",
    "        x = real.detach().requires_grad_(True)\n",
    "        preds = self.model.critic(x).mean()\n",
    "\n",
    "        grads = torch.autograd.grad(outputs=preds, inputs=x, create_graph=True)[0]\n",
    "        #return weight * (grads.norm()**2)  \n",
    "        # (flat+dot product) seems more efficient than norm**2\n",
    "        flat_grads = grads.view(-1)\n",
    "        return weight * flat_grads.dot(flat_grads)\n",
    "    \n",
    "        \n",
    "    def after_loss(self):\n",
    "        if not self.gan_trainer.gen_mode:\n",
    "            # In critic mode, GANTrainer swaps x and y; so, here x is original y (real target)\n",
    "            real = self.x\n",
    "            # Updated to fastai version 2.2.7: backward isn't called on learn.loss anymore, \n",
    "            # but on learn.loss_grad\n",
    "            self.learn.loss_grad += self._gradient_penalty(real, self.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_bns(m):\n",
    "    idxs_to_drop = []\n",
    "    for i, child in enumerate(m.children()):\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            idxs_to_drop.append(i)\n",
    "        else:\n",
    "            drop_bns(child)\n",
    "    for idx in idxs_to_drop: m[idx] = nn.Identity()\n",
    "        \n",
    "def replace_encoder_bn(m, affine=True):\n",
    "    idxs_to_replace = []\n",
    "    for i, child in enumerate(m.children()):\n",
    "        if isinstance(child, UnetBlock): break\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            idxs_to_replace.append(i)\n",
    "        else:\n",
    "            replace_encoder_bn(child, affine)\n",
    "    for idx in idxs_to_replace: \n",
    "        m[idx] = InstanceNorm(m[idx].num_features, affine=affine)\n",
    "        \n",
    "def replace_decoder_bn(unet):\n",
    "    for l in unet.layers:\n",
    "        if isinstance(l, UnetBlock):\n",
    "            l.bn = InstanceNorm(l.bn.num_features, affine=True)    \n",
    "        \n",
    "def replace_unet_bn(unet):\n",
    "    replace_encoder_bn(unet)\n",
    "    replace_decoder_bn(unet)\n",
    "        \n",
    "def drop_decoder_bn(unet):\n",
    "    for l in unet.layers:\n",
    "        if isinstance(l, UnetBlock):\n",
    "            l.bn = nn.Identity()\n",
    "            \n",
    "def add_sn(m):\n",
    "    idxs_to_edit = []\n",
    "    for i, l in enumerate(m.children()):\n",
    "        if isinstance(l, nn.Conv2d) or isinstance(l, nn.ConvTranspose2d):\n",
    "            idxs_to_edit.append(i)\n",
    "        add_sn(l)\n",
    "    for i in idxs_to_edit:\n",
    "        m[i] = spectral_norm(m[i])\n",
    "        \n",
    "        \n",
    "def set_act_inplace(m:nn.Module, act_cls=nn.ReLU, act_cls_set=nn.ReLU):\n",
    "    if isinstance(m, nn.Sequential) or isinstance(m, nn.ModuleList):\n",
    "        idxs_to_modify = []\n",
    "        for i in range(len(m)):\n",
    "            if isinstance(m[i], act_cls):\n",
    "                idxs_to_modify.append(i)\n",
    "            elif len(list(m[i].children())) > 0:\n",
    "                set_act_inplace(m[i], act_cls, act_cls_set)\n",
    "        for i in idxs_to_modify:\n",
    "            m[i] = act_cls_set(inplace=True)        \n",
    "    elif len(list(m.children())) > 0:\n",
    "        for attr_name in dir(m):\n",
    "            attr_value = getattr(m, attr_name)\n",
    "            if isinstance(attr_value, act_cls):\n",
    "                setattr(m, attr_name, act_cls_set(inplace=True))\n",
    "            elif isinstance(attr_value, nn.Module) and (len(list(attr_value.children())) > 0):\n",
    "                set_act_inplace(attr_value, act_cls, act_cls_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_types = [nn.Conv1d, nn.Conv2d, nn.Conv3d,\n",
    "              nn.ConvTranspose1d, nn.ConvTranspose2d, nn.ConvTranspose3d]\n",
    "\n",
    "def is_conv(m:nn.Module):\n",
    "    return any(isinstance(m, conv_type) for conv_type in conv_types)\n",
    "\n",
    "def has_sn_hook(m:nn.Module):\n",
    "    return any(isinstance(h, SpectralNorm) \n",
    "               for h in m._forward_pre_hooks.values())\n",
    "\n",
    "def every_conv_has_sn(module:nn.Module):\n",
    "    for m in module.modules():\n",
    "        if is_conv(m) and not has_sn_hook(m):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_iterable(x):\n",
    "    try:\n",
    "        iterator = iter(x)\n",
    "    except TypeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def get_mean_weights(m, layer_types):\n",
    "    all_modules_dict = dict(m.named_modules())\n",
    "    result = {}\n",
    "    for param_name, param in m.named_parameters():\n",
    "        module = all_modules_dict[param_name.rsplit('.', 1)[0]]\n",
    "        if isinstance(module, layer_types):\n",
    "            result[param_name] = param.data.abs().mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class MiniResBlock(nn.Module):\n",
    "    def __init__(self, in_ftrs, out_ftrs, norm_type=None, act_cls=nn.ReLU, **conv_kwargs):\n",
    "        super().__init__()\n",
    "        norm_type = (NormType.BatchZero if norm_type==NormType.Batch else\n",
    "                     NormType.InstanceZero if norm_type==NormType.Instance \n",
    "                     else norm_type)\n",
    "        self.convpath = ConvLayer(in_ftrs, out_ftrs, norm_type=norm_type, act_cls=act_cls,\n",
    "                                  **conv_kwargs)\n",
    "        self.act = act_cls()\n",
    "        \n",
    "    def forward(self, x): return self.act(self.convpath(x) + x)\n",
    "\n",
    "\n",
    "class ConcatPool2d(Module):\n",
    "    \"Layer that concats `AvgPool2d` and `MaxPool2d`\"\n",
    "    def __init__(self, ks, stride=None, padding=0):\n",
    "        self.ap = nn.AvgPool2d(ks, stride, padding)\n",
    "        self.mp = nn.MaxPool2d(ks, stride, padding)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "\n",
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    \"\"\"BN layer whose gain (gamma) and bias (beta) params also depend on an external condition vector.\"\"\"\n",
    "    def __init__(self, n_ftrs:int, cond_sz:int, gain_init:Callable=None, bias_init:Callable=None):\n",
    "        super().__init__()\n",
    "        self.n_ftrs = n_ftrs\n",
    "        # Don't learn beta and gamma inside self.bn (fix to irrelevance: beta=1, gamma=0)\n",
    "        self.bn = nn.BatchNorm2d(n_ftrs, affine=False)\n",
    "        self.gain = nn.Linear(cond_sz, n_ftrs, bias=False)\n",
    "        self.bias = nn.Linear(cond_sz, n_ftrs, bias=False)        \n",
    "        if gain_init is None: gain_init = nn.init.zeros_\n",
    "        if bias_init is None: bias_init = nn.init.zeros_\n",
    "        init_default(self.gain, gain_init)\n",
    "        init_default(self.bias, bias_init)\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        out = self.bn(x)\n",
    "        gamma = 1 + self.gain(cond)\n",
    "        beta = self.bias(cond)\n",
    "        out = gamma.view(-1, self.n_ftrs, 1, 1) * out + beta.view(-1, self.n_ftrs, 1, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CondConvLayer(nn.Module):\n",
    "    \"Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and conditional `norm_type` layers.\"\n",
    "    @delegates(nn.Conv2d)\n",
    "    def __init__(self, ni, nf, cond_sz, ks=3, stride=1, padding=None, bias=None, ndim=2, \n",
    "                 norm_type=NormType.Batch, bn_1st=True, act_cls=defaults.activation, \n",
    "                 transpose=False, init='auto', xtra=None, xtra_begin=None, bias_std=0.01, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if padding is None: padding = ((ks-1)//2 if not transpose else 0)\n",
    "        bn = norm_type in (NormType.Batch, NormType.BatchZero)\n",
    "        inn = norm_type in (NormType.Instance, NormType.InstanceZero)\n",
    "        if bias is None: bias = not (bn or inn)\n",
    "        conv_func = nn.ConvTranspose2d if transpose else nn.Conv2d\n",
    "        conv = conv_func(ni, nf, kernel_size=ks, bias=bias, stride=stride, padding=padding, **kwargs)\n",
    "        act = None if act_cls is None else act_cls()\n",
    "        init_linear(conv, act, init=init, bias_std=bias_std)\n",
    "        if   norm_type==NormType.Weight:   conv = weight_norm(conv)\n",
    "        elif norm_type==NormType.Spectral: conv = spectral_norm(conv)\n",
    "        self.layers = nn.ModuleList([conv])\n",
    "        act_bn = []\n",
    "        if act is not None: act_bn.append(act)\n",
    "        if bn: act_bn.append(ConditionalBatchNorm2d(nf, cond_sz))\n",
    "        # TODO: implement Conditional/AdaptiveInstanceNorm\n",
    "        if inn: act_bn.append(InstanceNorm(nf, norm_type=norm_type, ndim=ndim))\n",
    "        if bn_1st: act_bn.reverse()\n",
    "        self.layers += act_bn\n",
    "        if xtra_begin: self.layers.insert(0, xtra_begin)\n",
    "        if xtra: self.layers.append(xtra)\n",
    "    \n",
    "    def forward(self, x, cond):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l, ConditionalBatchNorm2d):\n",
    "                x = l(x, cond)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class DownsamplingOperation2d(ABC):\n",
    "    @abstractmethod\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        \"Must return a layer that increases the size of the last 2d of the input\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "class AvgPoolHalfDownsamplingOp2d(DownsamplingOperation2d):\n",
    "    def __init__(self, conv_ks=3, act_cls=None, norm_type=None):\n",
    "        self.conv_ks = conv_ks\n",
    "        self.act_cls = act_cls\n",
    "        self.norm_type = norm_type\n",
    "\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        layers = [nn.AvgPool2d(2)]\n",
    "        if out_ftrs != in_ftrs:\n",
    "            layers.append(ConvLayer(in_ftrs, out_ftrs, ks=self.conv_ks, act_cls=self.act_cls,\n",
    "                                    norm_type=self.norm_type, **op_kwargs))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "class ConcatPoolHalfDownsamplingOp2d(DownsamplingOperation2d):\n",
    "    def __init__(self, conv_ks=3, act_cls=None, norm_type=None, always_add_conv=False):\n",
    "        self.conv_ks = conv_ks\n",
    "        self.act_cls = act_cls\n",
    "        self.norm_type = norm_type\n",
    "        self.always_add_conv = always_add_conv\n",
    "\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        layers = [ConcatPool2d(2)]\n",
    "        if (out_ftrs != (in_ftrs*2)) or self.always_add_conv:\n",
    "            layers.append(ConvLayer(in_ftrs*2, out_ftrs, ks=self.conv_ks, act_cls=self.act_cls,\n",
    "                                    norm_type=self.norm_type, **op_kwargs))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "class ConvHalfDownsamplingOp2d(DownsamplingOperation2d):\n",
    "    def __init__(self, ks=4, padding=1, act_cls:Type[nn.Module]=None, norm_type=None,\n",
    "                 bn_1st=True):\n",
    "        self.ks=ks\n",
    "        self.act_cls = act_cls\n",
    "        self.padding = padding\n",
    "        self.norm_type = norm_type\n",
    "        self.bn_1st = bn_1st\n",
    "\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        assert (in_ftrs is not None) and (out_ftrs is not None), \\\n",
    "            \"in_ftrs and out_ftrs must both be valued for this UpsamplingOperation\"\n",
    "        if 'act_cls' not in op_kwargs:\n",
    "            op_kwargs['act_cls'] = self.act_cls\n",
    "        if 'norm_type' not in op_kwargs:\n",
    "            op_kwargs['norm_type'] = self.norm_type\n",
    "        if 'padding' not in op_kwargs:\n",
    "            op_kwargs['padding'] = self.padding\n",
    "#         conv = ConvLayer(in_ftrs, out_ftrs, self.ks, 2, bias=False, bn_1st=self.bn_1st,\n",
    "#                          **op_kwargs)\n",
    "        conv = ConvLayer(in_ftrs, out_ftrs, self.ks, 2, bn_1st=self.bn_1st,\n",
    "                         **op_kwargs)\n",
    "        return conv\n",
    "\n",
    "\n",
    "class UpsamplingOperation2d(ABC):\n",
    "    @abstractmethod\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        \"Must return a layer that increases the size of the last 2d of the input\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "class PixelShuffleUpsamplingOp2d(UpsamplingOperation2d):\n",
    "    def __init__(self, scale_factor=2, blur=False, n_extra_convs=0, act_cls:Type[nn.Module]=None, norm_type=None):\n",
    "        self.scale_factor = scale_factor\n",
    "        self.blur = blur\n",
    "        self.n_extra_convs = n_extra_convs\n",
    "        self.act_cls = act_cls\n",
    "        self.norm_type = norm_type\n",
    "    \n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs):\n",
    "        if 'act_cls' not in op_kwargs:\n",
    "            op_kwargs['act_cls'] = self.act_cls\n",
    "        if 'blur' not in op_kwargs:\n",
    "            op_kwargs['blur'] = self.blur\n",
    "        if 'norm_type' not in op_kwargs:\n",
    "            op_kwargs['norm_type'] = self.norm_type\n",
    "        layer = PixelShuffle_ICNR(in_ftrs, out_ftrs, self.scale_factor, **op_kwargs)\n",
    "        if self.n_extra_convs > 0:\n",
    "            extra_convs = [ConvLayer(out_ftrs, out_ftrs, norm_type=self.norm_type)\n",
    "                           for _ in range(self.n_extra_convs)]\n",
    "            layer = nn.Sequential(layer, *extra_convs)\n",
    "        return layer\n",
    "\n",
    "    \n",
    "class InterpConvUpsamplingOp2d(UpsamplingOperation2d):\n",
    "    def __init__(self, scale_factor=2, mode='nearest', ks=3, act_cls:Type[nn.Module]=None,\n",
    "                 norm_type=NormType.Batch, bn_1st=True):\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.act_cls = act_cls\n",
    "        self.ks = ks\n",
    "        self.norm_type = norm_type\n",
    "        self.bn_1st = bn_1st\n",
    "\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        if 'act_cls' not in op_kwargs:\n",
    "            op_kwargs['act_cls'] = self.act_cls\n",
    "        if 'norm_type' not in op_kwargs:\n",
    "            op_kwargs['norm_type'] = self.norm_type\n",
    "        return nn.Sequential(nn.Upsample(scale_factor=self.scale_factor, mode=self.mode),\n",
    "                             ConvLayer(in_ftrs, out_ftrs, self.ks, bn_1st=self.bn_1st, \n",
    "                                       **op_kwargs))\n",
    "\n",
    "\n",
    "class CondInterpConvUpsamplingOp2d(UpsamplingOperation2d):\n",
    "    def __init__(self, cond_sz, scale_factor=2, mode='nearest', ks=3, act_cls:Type[nn.Module]=None,\n",
    "                 norm_type=NormType.Batch, bn_1st=True):\n",
    "        self.cond_sz = cond_sz\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.act_cls = act_cls\n",
    "        self.ks = ks\n",
    "        self.norm_type = norm_type\n",
    "        self.bn_1st = bn_1st\n",
    "\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        if 'act_cls' not in op_kwargs:\n",
    "            op_kwargs['act_cls'] = self.act_cls\n",
    "        if 'norm_type' not in op_kwargs:\n",
    "            op_kwargs['norm_type'] = self.norm_type\n",
    "        upsample = nn.Upsample(scale_factor=self.scale_factor, mode=self.mode)\n",
    "        return CondConvLayer(in_ftrs, out_ftrs, self.cond_sz, self.ks, bn_1st=self.bn_1st, \n",
    "                             xtra_begin=upsample, **op_kwargs)\n",
    "\n",
    "\n",
    "class ConvX2UpsamplingOp2d(UpsamplingOperation2d):\n",
    "    def __init__(self, ks=4, act_cls:Type[nn.Module]=None, padding=1, output_padding=0,\n",
    "                 norm_type=NormType.Batch, bn_1st=True):\n",
    "        #self.apply_sn = apply_sn\n",
    "        self.ks=ks\n",
    "        self.act_cls = act_cls\n",
    "        self.padding = padding\n",
    "        self.output_padding = output_padding\n",
    "        self.norm_type = norm_type\n",
    "        self.bn_1st=bn_1st\n",
    "\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        assert (in_ftrs is not None) and (out_ftrs is not None), \\\n",
    "            \"in_ftrs and out_ftrs must both be valued for this UpsamplingOperation\"\n",
    "        if 'act_cls' not in op_kwargs:\n",
    "            op_kwargs['act_cls'] = self.act_cls\n",
    "        if 'norm_type' not in op_kwargs:\n",
    "            op_kwargs['norm_type'] = self.norm_type\n",
    "        conv = ConvLayer(in_ftrs, out_ftrs, self.ks, 2, self.padding, transpose=True, \n",
    "                         bias=False, output_padding=self.output_padding, bn_1st=self.bn_1st,\n",
    "                         **op_kwargs)\n",
    "#         if self.apply_sn and (op_kwargs.get('norm_type') != NormType.Spectral): \n",
    "#             add_sn(conv)\n",
    "        return conv\n",
    "\n",
    "\n",
    "class CondConvX2UpsamplingOp2d(UpsamplingOperation2d):\n",
    "    def __init__(self, cond_sz, ks=4, act_cls:Type[nn.Module]=None, padding=1, output_padding=0,\n",
    "                 norm_type=NormType.Batch, bn_1st=True):\n",
    "        self.cond_sz = cond_sz\n",
    "        self.ks=ks\n",
    "        self.act_cls = act_cls\n",
    "        self.padding = padding\n",
    "        self.output_padding = output_padding\n",
    "        self.norm_type = norm_type\n",
    "        self.bn_1st=bn_1st\n",
    "\n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        assert (in_ftrs is not None) and (out_ftrs is not None), \\\n",
    "            \"in_ftrs and out_ftrs must both be valued for this UpsamplingOperation\"\n",
    "        if 'act_cls' not in op_kwargs:\n",
    "            op_kwargs['act_cls'] = self.act_cls\n",
    "        if 'norm_type' not in op_kwargs:\n",
    "            op_kwargs['norm_type'] = self.norm_type\n",
    "        conv = CondConvLayer(in_ftrs, out_ftrs, self.cond_sz, self.ks, 2, self.padding, \n",
    "                             transpose=True, bias=False, output_padding=self.output_padding, \n",
    "                             bn_1st=self.bn_1st, **op_kwargs)\n",
    "        return conv\n",
    "\n",
    "\n",
    "def custom_generator(out_size, n_channels, up_op:UpsamplingOperation2d, in_sz=100, \n",
    "                     n_features=64, n_extra_layers=0, sn=True, **kwargs):\n",
    "    \"A basic generator from `in_sz` to images `n_channels` x `out_size` x `out_size`.\"\n",
    "    cur_size, cur_ftrs = 4, n_features//2\n",
    "    while cur_size < out_size:  cur_size *= 2; cur_ftrs *= 2\n",
    "    layers = [AddChannels(2), ConvLayer(in_sz, cur_ftrs, 4, 1, transpose=True, **kwargs)]\n",
    "    cur_size = 4\n",
    "    while cur_size < out_size // 2:\n",
    "        layers.append(up_op.get_layer(cur_ftrs, cur_ftrs//2, **kwargs))\n",
    "        cur_ftrs //= 2; cur_size *= 2\n",
    "    layers += [ConvLayer(cur_ftrs, cur_ftrs, 3, 1, 1, transpose=True, **kwargs) for _ in range(n_extra_layers)]\n",
    "    layers += [up_op.get_layer(cur_ftrs, n_channels, norm_type=None, act_cls=None), nn.Tanh()]\n",
    "    generator = nn.Sequential(*layers)\n",
    "    if sn: add_sn(generator)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlockUp(nn.Module):\n",
    "    def __init__(self, in_ftrs, out_ftrs, up_op:UpsamplingOperation2d, \n",
    "                 id_up_op:UpsamplingOperation2d, n_extra_convs=1, \n",
    "                 upsample_first=True, norm_type=NormType.Batch, \n",
    "                 act_cls=nn.ReLU, bn_1st=True, **up_op_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "#         norm2 = (NormType.BatchZero if norm_type==NormType.Batch else\n",
    "#                  NormType.InstanceZero if norm_type==NormType.Instance \n",
    "#                  else norm_type)\n",
    "        up_layer = up_op.get_layer(in_ftrs, out_ftrs, **up_op_kwargs)\n",
    "        extra_convs_ftrs = out_ftrs if upsample_first else in_ftrs\n",
    "        inner_path_ls = ([ConvLayer(extra_convs_ftrs, extra_convs_ftrs, bn_1st=bn_1st, norm_type=norm_type,\n",
    "                                    #norm_type=norm_type if ((i<n_extra_convs-1) or not upsample_first) else norm2,\n",
    "                                    act_cls=act_cls if ((i<n_extra_convs-1) or (not upsample_first) or (not bn_1st)) else None)\n",
    "                         for i in range(n_extra_convs)])\n",
    "        inner_path_ls.insert(0 if upsample_first else len(inner_path_ls),\n",
    "                            up_layer)\n",
    "        self.inner_path = nn.Sequential(*inner_path_ls)\n",
    "        \n",
    "        self.id_path = id_up_op.get_layer(in_ftrs, out_ftrs)\n",
    "        \n",
    "        self.act = defaults.activation(inplace=True) if act_cls is None else act_cls()\n",
    "        \n",
    "    def forward(self, x): return self.act(self.inner_path(x) + self.id_path(x))\n",
    "    \n",
    "\n",
    "class RescaledResBlockUp(ResBlockUp):\n",
    "    def forward(self, x): return self.act((self.inner_path(x) + self.id_path(x)) / 2)\n",
    "    \n",
    "\n",
    "class DenseBlockUp(ResBlockUp):\n",
    "    def __init__(self, in_ftrs, out_ftrs, up_op:UpsamplingOperation2d, \n",
    "                 id_up_op:UpsamplingOperation2d, n_extra_convs=1, \n",
    "                 upsample_first=True, norm_type=NormType.Batch, \n",
    "                 act_cls=nn.ReLU, bn_1st=True, **up_op_kwargs):\n",
    "        super().__init__(in_ftrs, out_ftrs, up_op, id_up_op, n_extra_convs=n_extra_convs, \n",
    "                         upsample_first=upsample_first, norm_type=norm_type, \n",
    "                         act_cls=act_cls, bn_1st=bn_1st, **up_op_kwargs)\n",
    "        \n",
    "        self.final_conv = ConvLayer(out_ftrs*2, out_ftrs, bn_1st=bn_1st, norm_type=norm_type,\n",
    "                                    act_cls=act_cls)       \n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.final_conv(self.act(torch.cat([self.inner_path(x), self.id_path(x)], axis=1)))\n",
    "\n",
    "\n",
    "class CondResBlockUp(nn.Module):\n",
    "    def __init__(self, in_ftrs, out_ftrs, cond_sz, up_op:UpsamplingOperation2d, \n",
    "                 id_up_op:UpsamplingOperation2d, n_extra_convs=1, \n",
    "                 upsample_first=True, norm_type=NormType.Batch, \n",
    "                 act_cls=nn.ReLU, bn_1st=True, **up_op_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        up_layer = up_op.get_layer(in_ftrs, out_ftrs, **up_op_kwargs)\n",
    "        extra_convs_ftrs = out_ftrs if upsample_first else in_ftrs\n",
    "        inner_path_ls = ([CondConvLayer(extra_convs_ftrs, extra_convs_ftrs, cond_sz, bn_1st=bn_1st, norm_type=norm_type,\n",
    "                                    act_cls=act_cls if ((i<n_extra_convs-1) or (not upsample_first) or (not bn_1st)) else None)\n",
    "                         for i in range(n_extra_convs)])\n",
    "        inner_path_ls.insert(0 if upsample_first else len(inner_path_ls),\n",
    "                            up_layer)\n",
    "        self.inner_path = nn.ModuleList(inner_path_ls)\n",
    "        \n",
    "        self.id_path = id_up_op.get_layer(in_ftrs, out_ftrs)\n",
    "        \n",
    "        self.act = defaults.activation(inplace=True) if act_cls is None else act_cls()\n",
    "        \n",
    "    def forward(self, x, cond): \n",
    "        inner_out = x\n",
    "        for l in self.inner_path:\n",
    "            inner_out = l(inner_out, cond)\n",
    "        return self.act(inner_out + self.id_path(x, cond))\n",
    "\n",
    "\n",
    "class ResBlockDown(nn.Module):\n",
    "    def __init__(self, in_ftrs, out_ftrs, down_op:DownsamplingOperation2d, \n",
    "                 id_down_op:DownsamplingOperation2d, n_extra_convs=1,\n",
    "                 downsample_first=False, norm_type=NormType.Batch, \n",
    "                 act_cls=partial(nn.LeakyReLU, negative_slope=0.2),\n",
    "                 bn_1st=True, **down_op_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "#         norm2 = (NormType.BatchZero if norm_type==NormType.Batch else\n",
    "#                  NormType.InstanceZero if norm_type==NormType.Instance \n",
    "#                  else norm_type)\n",
    "        down_layer = down_op.get_layer(in_ftrs, out_ftrs, **down_op_kwargs)\n",
    "        extra_convs_ftrs = out_ftrs if downsample_first else in_ftrs\n",
    "        inner_path_ls = ([ConvLayer(extra_convs_ftrs, extra_convs_ftrs, bn_1st=bn_1st, norm_type=norm_type,\n",
    "                                    #norm_type=norm_type if ((i<n_extra_convs-1) or not downsample_first) else norm2,\n",
    "                                    act_cls=act_cls if ((i<n_extra_convs-1) or (not downsample_first) or (not bn_1st)) else None)\n",
    "                         for i in range(n_extra_convs)])\n",
    "        inner_path_ls.insert(0 if downsample_first else len(inner_path_ls),\n",
    "                            down_layer)\n",
    "        self.inner_path = nn.Sequential(*inner_path_ls)\n",
    "        \n",
    "        self.id_path = id_down_op.get_layer(in_ftrs, out_ftrs, bias=False)\n",
    "        \n",
    "        self.act = defaults.activation(inplace=True) if act_cls is None else act_cls()\n",
    "        \n",
    "    def forward(self, x): return self.act(self.inner_path(x) + self.id_path(x))\n",
    "    \n",
    "\n",
    "class RescaledResBlockDown(ResBlockDown):\n",
    "    def forward(self, x): return self.act((self.inner_path(x) + self.id_path(x)) / 2)\n",
    "    \n",
    "    \n",
    "class PseudoDenseBlockDown(ResBlockDown):\n",
    "    def __init__(self, in_ftrs, out_ftrs, down_op:DownsamplingOperation2d, \n",
    "                 id_down_op:DownsamplingOperation2d, n_extra_convs=1,\n",
    "                 downsample_first=False, norm_type=NormType.Batch, \n",
    "                 act_cls=partial(nn.LeakyReLU, negative_slope=0.2),\n",
    "                 bn_1st=True, **down_op_kwargs):\n",
    "        super().__init__(in_ftrs, out_ftrs//2, down_op, id_down_op, n_extra_convs=n_extra_convs,\n",
    "                         downsample_first=downsample_first, norm_type=norm_type, \n",
    "                         act_cls=act_cls, bn_1st=bn_1st, **down_op_kwargs)      \n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.act(torch.cat([self.inner_path(x), self.id_path(x)], axis=1)) \n",
    "    \n",
    "    \n",
    "class DenseBlockDown(ResBlockDown):\n",
    "    def __init__(self, in_ftrs, out_ftrs, down_op:DownsamplingOperation2d, \n",
    "                 id_down_op:DownsamplingOperation2d, n_extra_convs=1,\n",
    "                 downsample_first=False, norm_type=NormType.Batch, \n",
    "                 act_cls=partial(nn.LeakyReLU, negative_slope=0.2),\n",
    "                 bn_1st=True, **down_op_kwargs):\n",
    "        super().__init__(in_ftrs, out_ftrs, down_op, id_down_op, n_extra_convs=n_extra_convs,\n",
    "                         downsample_first=downsample_first, norm_type=norm_type, \n",
    "                         act_cls=act_cls, bn_1st=bn_1st, **down_op_kwargs)\n",
    "        \n",
    "        self.final_conv = ConvLayer(out_ftrs*2, out_ftrs, bn_1st=bn_1st, norm_type=norm_type,\n",
    "                                    act_cls=act_cls)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.final_conv(self.act(torch.cat([self.inner_path(x), self.id_path(x)], axis=1)))\n",
    "\n",
    "\n",
    "def res_generator(out_sz, n_ch, up_op:UpsamplingOperation2d, id_up_op:UpsamplingOperation2d,\n",
    "                  in_sz=100, n_features=64, n_extra_res_blocks=1, n_extra_convs_by_res_block=1,\n",
    "                  sn=True, bn_1st=True, upblock_cls=ResBlockUp, **kwargs):\n",
    "    cur_sz, cur_ftrs = 4, n_features//2\n",
    "    while cur_sz < out_sz:  cur_sz *= 2; cur_ftrs *= 2\n",
    "    layers = [AddChannels(2), \n",
    "              ConvLayer(in_sz, cur_ftrs, 4, 1, transpose=True, bn_1st=bn_1st, **kwargs)]\n",
    "    cur_sz = 4\n",
    "    while cur_sz < out_sz // 2:\n",
    "        layers.append(upblock_cls(cur_ftrs, cur_ftrs//2, up_op, id_up_op, \n",
    "                                  n_extra_convs=n_extra_convs_by_res_block,\n",
    "                                  bn_1st=bn_1st, **kwargs))\n",
    "        cur_ftrs //= 2; cur_sz *= 2\n",
    "    layers += [ResBlock(1, cur_ftrs, cur_ftrs, bn_1st=bn_1st, **kwargs) \n",
    "               for _ in range(n_extra_res_blocks)]\n",
    "    layers += [up_op.get_layer(cur_ftrs, n_ch, norm_type=None, act_cls=None), nn.Tanh()]\n",
    "    generator = nn.Sequential(*layers)\n",
    "    if sn: add_sn(generator)\n",
    "    return generator\n",
    "\n",
    "\n",
    "class NoiseSplitStrategy(ABC):    \n",
    "    @abstractmethod\n",
    "    def calc_cond_sz(self, noise_sz, n_splits):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def split_noise(self, noise, n_splits):\n",
    "        pass\n",
    "\n",
    "\n",
    "class NoiseSplitEqualLeave1stOutStrategy(NoiseSplitStrategy):     \n",
    "    def calc_cond_sz(self, noise_sz, n_splits):\n",
    "        # Divide by `n_splits+1` to next leave first chunk out of conditions\n",
    "        return noise_sz // (n_splits + 1)\n",
    "        \n",
    "    def split_noise(self, noise, n_splits):\n",
    "        noise_sz = noise.shape[1]\n",
    "        cond_sz = self.calc_cond_sz(noise_sz, n_splits)\n",
    "        return noise.split(cond_sz, 1)[1:]\n",
    "    \n",
    "    \n",
    "class NoiseSplitDontSplitStrategy(NoiseSplitStrategy):\n",
    "    def calc_cond_sz(self, noise_sz, n_splits):\n",
    "        return noise_sz\n",
    "        \n",
    "    def split_noise(self, noise, n_splits):\n",
    "        return [noise] * n_splits\n",
    "\n",
    "\n",
    "class CondResGenerator(nn.Module):\n",
    "    init_sz = 4\n",
    "    \n",
    "    def __init__(self, out_sz, n_ch, up_op:UpsamplingOperation2d, id_up_op:UpsamplingOperation2d, \n",
    "                 noise_split_strategy, in_sz=100, n_features=64, n_extra_res_blocks=1, \n",
    "                 n_extra_convs_by_res_block=1, sn=True, bn_1st=True, upblock_cls=CondResBlockUp,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.noise_split_strategy = noise_split_strategy\n",
    "        cur_sz, cur_ftrs = self.init_sz, n_features//2\n",
    "        while cur_sz < out_sz:  cur_sz *= 2; cur_ftrs *= 2\n",
    "        self.initial_layers = nn.Sequential(\n",
    "            AddChannels(2), \n",
    "            ConvLayer(in_sz, cur_ftrs, 4, 1, transpose=True, bn_1st=bn_1st, **kwargs))\n",
    "        cur_sz = self.init_sz\n",
    "        n_splits = self.calc_n_upblocks(out_sz)\n",
    "        self.cond_sz = noise_split_strategy.calc_cond_sz(in_sz, n_splits)\n",
    "        self.up_layers = nn.ModuleList([])\n",
    "        while cur_sz < out_sz // 2:\n",
    "            self.up_layers.append(upblock_cls(cur_ftrs, cur_ftrs//2, self.cond_sz, \n",
    "                                              up_op, id_up_op, bn_1st=bn_1st, \n",
    "                                              n_extra_convs=n_extra_convs_by_res_block,\n",
    "                                              **kwargs))\n",
    "            cur_ftrs //= 2; cur_sz *= 2\n",
    "            \n",
    "        self.extra_blocks = nn.Sequential(\n",
    "            *[ResBlock(1, cur_ftrs, cur_ftrs, bn_1st=bn_1st, **kwargs) \n",
    "              for _ in range(n_extra_res_blocks)])\n",
    "        self.final_conv = up_op.get_layer(cur_ftrs, n_ch, norm_type=None, act_cls=None)\n",
    "        self.act = nn.Tanh()\n",
    "        if sn: \n",
    "            add_sn(self.initial_layers)\n",
    "            for up_l in self.up_layers: add_sn(up_l)\n",
    "            add_sn(self.extra_blocks)\n",
    "            add_sn(self.final_conv)\n",
    "    \n",
    "    @classmethod\n",
    "    def calc_n_upblocks(cls, out_sz):\n",
    "        return int(math.log2(out_sz // (2 * cls.init_sz)))\n",
    "    \n",
    "    def forward(self, z):\n",
    "        n_splits = len(self.up_layers)\n",
    "        z_splits = self.noise_split_strategy.split_noise(z, n_splits)\n",
    "        x = self.initial_layers(z)\n",
    "        for zi, up_layer in zip(z_splits, self.up_layers):\n",
    "            x = up_layer(x, zi)\n",
    "        x = self.extra_blocks(x)\n",
    "        return self.act(self.final_conv(x, None))\n",
    "\n",
    "    \n",
    "class SkipGenerator(nn.Module):\n",
    "    def __init__(self, out_sz, n_ch, up_op:UpsamplingOperation2d, id_up_op:UpsamplingOperation2d,\n",
    "                 in_sz=100, n_features=64, n_extra_res_blocks=1, n_extra_convs_by_res_block=1,\n",
    "                 sn=True, bn_1st=True, upblock_cls=ResBlockUp, upsample_skips_mode='nearest',\n",
    "                 skip2rgb_ks=3, skip_act_cls=nn.Tanh, **kwargs):\n",
    "        super().__init__()\n",
    "        cur_sz, cur_ftrs = 4, n_features//2\n",
    "        while cur_sz < out_sz:  cur_sz *= 2; cur_ftrs *= 2\n",
    "        self.initial_layers = nn.Sequential(\n",
    "            AddChannels(2), \n",
    "            ConvLayer(in_sz, cur_ftrs, 4, 1, transpose=True, bn_1st=bn_1st, **kwargs))\n",
    "        cur_sz = 4\n",
    "        self.up_layers = nn.ModuleList([])\n",
    "        self.skips_torgb = nn.ModuleList([])\n",
    "        self.upsample_skips_mode = upsample_skips_mode\n",
    "        while cur_sz < out_sz // 2:\n",
    "            self.up_layers.append(upblock_cls(cur_ftrs, cur_ftrs//2, up_op, id_up_op, \n",
    "                                              n_extra_convs=n_extra_convs_by_res_block,\n",
    "                                              bn_1st=bn_1st, **kwargs))\n",
    "            self.skips_torgb.append(ConvLayer(cur_ftrs//2, n_ch, ks=skip2rgb_ks, norm_type=None,\n",
    "                                              act_cls=skip_act_cls, bias=False))\n",
    "            cur_ftrs //= 2; cur_sz *= 2\n",
    "        self.extra_blocks = nn.Sequential(\n",
    "            *[ResBlock(1, cur_ftrs, cur_ftrs, bn_1st=bn_1st, **kwargs) \n",
    "              for _ in range(n_extra_res_blocks)])\n",
    "        self.last_up = up_op.get_layer(cur_ftrs, n_ch, norm_type=None, act_cls=None)\n",
    "        self.act = nn.Tanh()\n",
    "        if sn: \n",
    "            add_sn(nn.Sequential(self.initial_layers, self.up_layers, self.skips_torgb,\n",
    "                                 self.extra_blocks, self.last_up))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.initial_layers(x)\n",
    "        out = None\n",
    "        for up_layer, skip_torgb in zip(self.up_layers, self.skips_torgb):\n",
    "            x = up_layer(x)\n",
    "            skip_x = skip_torgb(x)\n",
    "            out = skip_x if out is None else out + skip_x\n",
    "            out = F.interpolate(out, scale_factor=2, mode=self.upsample_skips_mode)\n",
    "        x = self.extra_blocks(x)\n",
    "        x = self.last_up(x)\n",
    "        return self.act(out + x)\n",
    "    \n",
    "\n",
    "def res_critic(in_size, n_channels, down_op, id_down_op, n_features=64, n_extra_res_blocks=1, \n",
    "               norm_type=NormType.Batch, n_extra_convs_by_res_block=0, sn=True, bn_1st=True,\n",
    "               downblock_cls=ResBlockDown, flatten_full=False, **kwargs):\n",
    "    \"A basic critic for images `n_channels` x `in_size` x `in_size`.\"\n",
    "    layers = [down_op.get_layer(n_channels, n_features, norm_type=None, **kwargs)]\n",
    "    cur_size, cur_ftrs = in_size//2, n_features\n",
    "    layers += [ResBlock(1, cur_ftrs, cur_ftrs, norm_type=norm_type, bn_1st=bn_1st, **kwargs) \n",
    "               for _ in range(n_extra_res_blocks)]\n",
    "    while cur_size > 4:\n",
    "        layers.append(downblock_cls(cur_ftrs, cur_ftrs*2, down_op, id_down_op,\n",
    "                                    n_extra_convs=n_extra_convs_by_res_block,\n",
    "                                    norm_type=norm_type, bn_1st=bn_1st, **kwargs))\n",
    "        cur_ftrs *= 2 ; cur_size //= 2\n",
    "    init = kwargs.get('init', nn.init.kaiming_normal_)\n",
    "    #layers += [init_default(nn.Conv2d(cur_ftrs, 1, 4, padding=0, bias=False), init), Flatten()]    \n",
    "    layers += [init_default(nn.Conv2d(cur_ftrs, 1, 4, padding=0), init), Flatten(full=flatten_full)]\n",
    "    critic =  nn.Sequential(*layers)\n",
    "    if sn: add_sn(critic)\n",
    "    return critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1)\n",
    "generator = basic_generator(img_size, n_channels, in_sz=100, n_features=64, \n",
    "                            n_extra_layers=1)\n",
    "add_sn(critic)\n",
    "add_sn(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "critic, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAAverager():\n",
    "    def __init__(self, decay=0.999):\n",
    "        self.decay = decay\n",
    "        \n",
    "    def __call__(self, averaged_model_parameter, model_parameter, num_averaged):\n",
    "        return self.decay * averaged_model_parameter + (1 - self.decay) * model_parameter\n",
    "    \n",
    "\n",
    "class EMACallback(Callback):\n",
    "    def __init__(self, ema_model, orig_model, dl): \n",
    "        self.ema_model = ema_model\n",
    "        self.orig_model = orig_model\n",
    "        self.dl = dl\n",
    "        \n",
    "    def after_step(self):\n",
    "        if self.gan_trainer.gen_mode:\n",
    "            self.ema_model.update_parameters(self.orig_model)\n",
    "            \n",
    "    def after_fit(self):\n",
    "        torch.optim.swa_utils.update_bn(self.dl, self.ema_model)\n",
    "   \n",
    "        \n",
    "def add_ema_to_gan_learner(gan_learner, dblock, ds_path, decay=0.999):\n",
    "    generator = gan_learner.model.generator\n",
    "    ema_avg_fn = EMAAverager(decay=decay)\n",
    "    gan_learner.ema_model = torch.optim.swa_utils.AveragedModel(generator, avg_fn=ema_avg_fn)\n",
    "    clean_dls = dblock.dataloaders(ds_path, path=ds_path, bs=bs)\n",
    "    gan_learner.add_cb(EMACallback(gan_learner.ema_model, generator, clean_dls.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_save_model(learner, filename, base_path='/kaggle/working'):\n",
    "    if isinstance(base_path, str): base_path = Path(base_path)\n",
    "    if not isinstance(base_path, Path): raise Exception('Invalid base_path')\n",
    "    file = join_path_file(filename, base_path/learner.model_dir, ext='.pth')\n",
    "    save_model(file, learner.model, learner.opt)\n",
    "    if getattr(learn, 'ema_model', None) is not None:\n",
    "        save_ema_model(learner, base_path, filename)\n",
    "    \n",
    "\n",
    "def custom_load_model(learner, filename, with_opt=True, device=None, \n",
    "                      base_path='/kaggle/input/new-face2anime-weights', \n",
    "                      with_ema=False, **kwargs):\n",
    "    if isinstance(base_path, str): base_path = Path(base_path)\n",
    "    if not isinstance(base_path, Path): raise Exception('Invalid base_path')\n",
    "    if device is None and hasattr(learner.dls, 'device'): device = learner.dls.device\n",
    "    if learner.opt is None: learner.create_opt()\n",
    "    #file = join_path_file(filename, base_path/learner.model_dir, ext='.pth')\n",
    "    file = base_path/f'{filename}.pth'\n",
    "    load_model(file, learner.model, learner.opt, with_opt=with_opt, device=device, **kwargs)\n",
    "    if with_ema:\n",
    "        load_ema_model(learner, base_path, filename)\n",
    "\n",
    "    \n",
    "def load_ema_model(learner, base_path, filename, device=None):\n",
    "    ema_filename = base_path/f'{filename}_ema.pth'\n",
    "    load_model(ema_filename, learner.ema_model, None, with_opt=False, device=device)\n",
    "    #state_dict = torch.load(ema_filename)\n",
    "    #learner.ema_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def save_ema_model(learner, base_path, filename):\n",
    "    file = join_path_file(filename+'_ema', base_path/learner.model_dir, ext='.pth')\n",
    "    save_model(file, learner.ema_model, None, with_opt=False)\n",
    "    #torch.save(file, learner.ema_model.state_dict())    \n",
    "    \n",
    "    \n",
    "def predict_n(learner, n_imgs, max_bs=64):\n",
    "    dummy_path = Path('')\n",
    "    dl = learner.dls.test_dl([dummy_path]*n_imgs, bs=max_bs)   \n",
    "    inp, imgs_t, _, dec_imgs_t = learner.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "    dec_batch = dls.decode_batch((inp,) + tuplify(dec_imgs_t), max_n=n_imgs)\n",
    "    return dec_batch\n",
    "    \n",
    "def predict_show_n(learner, n_imgs, **predict_n_kwargs):\n",
    "    preds_batch = predict_n(learner, n_imgs, **predict_n_kwargs)\n",
    "    _, axs = plt.subplots(n_imgs, 2, figsize=(6, n_imgs * 3))\n",
    "    for i, (inp, pred_img) in enumerate(preds_batch):\n",
    "        inp.show(ax=axs[i][0])\n",
    "        pred_img.show(ax=axs[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 1: WGAN-GP lambda=10, basic G and C, SN+BN in G and C, 5 C/G iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_1(for_inference=False):\n",
    "    critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1)\n",
    "    generator = basic_generator(img_size, n_channels, in_sz=100, n_features=64, \n",
    "                                n_extra_layers=1)\n",
    "    add_sn(critic)\n",
    "    add_sn(generator)\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs)\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr1_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Show results after returning to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_1(for_inference=True)\n",
    "custom_load_model(learn, 'noise2img_tr1_10ep', with_opt=False)\n",
    "predict_show_n(learn, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 2: WGAN-GP lambda=0.1, basic G and C, SN+BN in G and C, 5 C/G iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_2(for_inference=False):\n",
    "    critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1)\n",
    "    generator = basic_generator(img_size, n_channels, in_sz=100, n_features=64, \n",
    "                                n_extra_layers=1)\n",
    "    add_sn(critic)\n",
    "    add_sn(generator)\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=0.1))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs)\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr2_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 3: WGAN-GP lambda=10, basic G and C, SN+BN in G and C, 5 C/G iters, leaky as C act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_3(for_inference=False):\n",
    "    critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1,\n",
    "                          act_cls=nn.modules.activation.LeakyReLU)\n",
    "    generator = basic_generator(img_size, n_channels, in_sz=100, n_features=64, \n",
    "                                n_extra_layers=1)\n",
    "    add_sn(critic)\n",
    "    add_sn(generator)\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs)\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr3_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 4: WGAN-GP lambda=100, basic G and C, SN+BN in G and C, 5 C/G iters, leaky as C act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_4(for_inference=False):\n",
    "    critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1,\n",
    "                          act_cls=nn.modules.activation.LeakyReLU)\n",
    "    generator = basic_generator(img_size, n_channels, in_sz=100, n_features=64, \n",
    "                                n_extra_layers=1)\n",
    "    add_sn(critic)\n",
    "    add_sn(generator)\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=100.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs)\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr4_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 5: WGAN-GP lambda=10, basic G and C, SN+BN in G and C, 1 C/G iters, leaky as C act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_5(for_inference=False):\n",
    "    critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1,\n",
    "                          act_cls=nn.modules.activation.LeakyReLU)\n",
    "    generator = basic_generator(img_size, n_channels, in_sz=100, n_features=64, \n",
    "                                n_extra_layers=1)\n",
    "    add_sn(critic)\n",
    "    add_sn(generator)\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher = FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr5_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_5()\n",
    "custom_load_model(learn, 'noise2img_tr5_8ep', base_path='./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, 5e-5)\n",
    "custom_save_model(learn, 'noise2img_tr5_10ep_low_lr', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 6: WGAN-GP lambda=10, basic G and C, SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with interp+conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_6(for_inference=False):\n",
    "    critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1,\n",
    "                          act_cls=nn.modules.activation.LeakyReLU)\n",
    "    generator = custom_generator(img_size, n_channels, InterpConvUpsamplingOp2d(act_cls=nn.ReLU),\n",
    "                                 in_sz=100, n_features=64, n_extra_layers=1, sn=True)\n",
    "    add_sn(critic)\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher = FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr6_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 7: WGAN-GP lambda=10, basic G and C, SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with PixelShuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_7(for_inference=False, n_convs_after_shuf=0, n_crit_per_g_iters=1):\n",
    "    critic = basic_critic(img_size, n_channels, n_features=64, n_extra_layers=1,\n",
    "                          act_cls=nn.modules.activation.LeakyReLU)\n",
    "    up_op = PixelShuffleUpsamplingOp2d(act_cls=nn.ReLU, norm_type=None,\n",
    "                                       n_extra_convs=n_convs_after_shuf)\n",
    "    generator = custom_generator(img_size, n_channels, up_op, in_sz=100, \n",
    "                                 n_features=64, n_extra_layers=1, sn=True)\n",
    "    add_sn(critic)\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=n_crit_per_g_iters, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn\n",
    "\n",
    "learn = create_learner_7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr7_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b: 1 extra conv after each PixelShuffle block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_7b(for_inference=False):\n",
    "    return create_learner_7(for_inference=for_inference,\n",
    "                            n_convs_after_shuf=1,\n",
    "                            n_crit_per_g_iters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_7b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave weight norm in convs inside PixelShuffle blocks\n",
    "for layer in (learn.model.generator[2][0][0][0],\n",
    "              learn.model.generator[3][0][0][0],\n",
    "              learn.model.generator[4][0][0][0],\n",
    "              learn.model.generator[6][0][0][0]):\n",
    "    torch.nn.utils.remove_spectral_norm(layer)\n",
    "    torch.nn.utils.weight_norm(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr7b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 8: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_8(for_inference=False):\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=partial(nn.LeakyReLU, negative_slope=0.2),\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0,\n",
    "                        act_cls=partial(nn.LeakyReLU, negative_slope=0.2))\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn\n",
    "\n",
    "learn = create_learner_8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.generator, learn.model.critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr8_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 9: WGAN-GP lambda=10, res G and C (1 xtra conv both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_9(for_inference=False):\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=partial(nn.LeakyReLU, negative_slope=0.2),\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=1,\n",
    "                        act_cls=partial(nn.LeakyReLU, negative_slope=0.2))\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn\n",
    "\n",
    "learn = create_learner_9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(every_conv_has_sn(learn.model.generator), every_conv_has_sn(learn.model.critic),\n",
    "learn.model.critic, learn.model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr9_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9b: 1 extra layer instead of 1 extra ResBlock in both C and G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_9b(*args, **kwargs): \n",
    "    learn = create_learner_9(*args, **kwargs)\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    learn.model.critic[1] = ConvLayer(64, 64, act_cls=leakyReLU02)\n",
    "    add_sn(learn.model.critic[1])\n",
    "    learn.model.generator[-3] = ConvLayer(64, 64, padding=1, transpose=True)\n",
    "    add_sn(learn.model.generator[-3])\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_9b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    " learn.model.critic, learn.model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr9b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 10 [TR 8 w/ coherent resblockDown]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_10(for_inference=False):\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=None, norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=NormType.Batch)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0,\n",
    "                        act_cls=partial(nn.LeakyReLU, negative_slope=0.2))\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_10()\n",
    "learn.model.critic, learn.model.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr10_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10b: w/o BN in ResBlockDown identity path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_10b(for_inference=False):\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=None, norm_type=NormType.BatchZero)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0,\n",
    "                        act_cls=partial(nn.LeakyReLU, negative_slope=0.2))\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_10b()\n",
    "learn.model.generator, learn.model.critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr10b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 11 [TR 8 w/ act b4 BN]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_11(for_inference=False):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_11()\n",
    "learn.model.generator, learn.model.critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr11_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11b: 1 extra layer instead of 1 extra ResBlock in both C and G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_11b(*args, **kwargs): \n",
    "    learn = create_learner_11(*args, **kwargs)\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    learn.model.critic[1] = ConvLayer(64, 64, act_cls=leakyReLU02, bn_1st=False)\n",
    "    add_sn(learn.model.critic[1])\n",
    "    learn.model.generator[-3] = ConvLayer(64, 64, padding=1, transpose=True, bn_1st=False)\n",
    "    add_sn(learn.model.generator[-3])\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_11b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.critic, learn.model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(learn.model.critic[2].inner_path[0][2].weight,\n",
    "learn.model.generator[2].inner_path[0][2].weight,\n",
    "learn.model.generator[2].inner_path[1][2].weight,\n",
    "learn.model.generator[2].id_path[1].weight,\n",
    "learn.model.generator[5][2].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr11b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 12 [TR 9 w/ act b4 BN]: WGAN-GP lambda=10, res G and C (1 xtra conv/block both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_12(for_inference=False):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=1, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_12()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator), \n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr12_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12b: 1 extra layer instead of 1 extra ResBlock in both C and G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_12b(*args, **kwargs): \n",
    "    learn = create_learner_12(*args, **kwargs)\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    learn.model.critic[1] = ConvLayer(64, 64, act_cls=leakyReLU02, bn_1st=False)\n",
    "    add_sn(learn.model.critic[1])\n",
    "    learn.model.generator[-3] = ConvLayer(64, 64, padding=1, transpose=True, bn_1st=False)\n",
    "    add_sn(learn.model.generator[-3])\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_12b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator), \n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr12b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 13 [TR 11 w/ AP+conv as down id_path]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_13(for_inference=False, id_down_conv_ks=3):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = AvgPoolHalfDownsamplingOp2d(conv_ks=id_down_conv_ks)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13a: ks=3 for conv inside id_path of downsampling res block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_13()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(learn.model.generator[1][2].weight,\n",
    "learn.model.generator[2].inner_path[0][2].weight,\n",
    "learn.model.generator[2].inner_path[1][2].weight,\n",
    "learn.model.generator[2].id_path[1].weight,\n",
    "learn.model.critic[2].inner_path[0][2].weight,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr13_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13b: ks=1 for conv inside id_path of downsampling res block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_13b(*args, **kwargs):\n",
    "    return create_learner_13(id_down_conv_ks=1, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_13b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr13b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 14 [TR 11 w/ Interp+conv as up id_path]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_14(for_inference=False, id_up_conv_ks=3):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=id_up_conv_ks, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14a: ks=3 for conv inside id_path of upsampling res block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_14()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(learn.model.generator[1][2].weight,\n",
    "learn.model.generator[2].inner_path[0][2].weight,\n",
    "learn.model.generator[2].inner_path[1][2].weight,\n",
    "learn.model.generator[2].id_path[1][1].weight,\n",
    "learn.model.critic[2].inner_path[0][2].weight,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr14_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(4, 5e-5)\n",
    "custom_save_model(learn, 'noise2img_tr14_14ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(6, 1e-5)\n",
    "custom_save_model(learn, 'noise2img_tr14_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14a2: lr={C:4e-4, G:1e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_14a2(*args, **kwargs):\n",
    "    learn = create_learner_14(*args, **kwargs)\n",
    "    learn.add_cb(GANDiscriminativeLR(mult_lr=4.))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_14a2()\n",
    "lr = 1e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(8, lr)\n",
    "custom_save_model(learn, 'noise2img_tr14a2_8ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2.5e-5\n",
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr14a2_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr14a2_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14b: ks=1 for conv inside id_path of upsampling res block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_14b(*args, **kwargs):\n",
    "    return create_learner_14(id_up_conv_ks=1, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_14b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr14b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 15 [TR 11 w/ Interp+conv as up op]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with (main:Interp+conv, id:ConvTr1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_15(for_inference=False, up_op_ks=3, up_op_act_cls=nn.ReLU,\n",
    "                      id_up_op_act_cls=None):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = InterpConvUpsamplingOp2d(ks=up_op_ks, act_cls=up_op_act_cls, bn_1st=False)\n",
    "    #up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=id_up_op_act_cls, padding=0, output_padding=1,\n",
    "                                    bn_1st=False)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15a: ks=3 for conv after interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_15()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(learn.model.generator[1][2].weight,\n",
    "learn.model.generator[2].inner_path[0][1][2].weight,\n",
    "learn.model.generator[2].inner_path[1][2].weight,\n",
    "learn.model.generator[2].id_path[1].weight,\n",
    "learn.model.critic[2].inner_path[0][2].weight,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr15_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15b: ks=1 for conv after interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_15b(*args, **kwargs):\n",
    "    return create_learner_15(up_op_ks=1, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_15b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr15b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15c: ks=3 for conv after interpolation, include act in upsampling id path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_15c(*args, **kwargs):\n",
    "    return create_learner_15(id_up_op_act_cls=nn.ReLU, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_15c()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr15c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15d: ks=3 for conv after interpolation, w/o act after interpolation+conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_15d(*args, **kwargs):\n",
    "    return create_learner_15(up_op_act_cls=None, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_15d()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr15d_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 16 [TR 11 w/ Interp+conv as up op and id up op]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with (main:Interp+conv, id:Interp+conv1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_16(for_inference=False, up_op_act_cls=nn.ReLU, id_up_op_act_cls=None):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = InterpConvUpsamplingOp2d(act_cls=up_op_act_cls, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=1, act_cls=id_up_op_act_cls, bn_1st=False)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16a: w/o activation in id path of upsampling blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_16()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(learn.model.generator[1][2].weight,\n",
    "learn.model.generator[2].inner_path[0][1][2].weight,\n",
    "learn.model.generator[2].inner_path[1][2].weight,\n",
    "learn.model.generator[2].id_path[1][1].weight,\n",
    "learn.model.critic[2].inner_path[0][2].weight,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr16_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16b: with activation in id path of upsampling blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_16b(*args, **kwargs):\n",
    "    return create_learner_16(id_up_op_act_cls=nn.ReLU, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_16b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr16b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 17 [TR 14 w/ dense G]: WGAN-GP lambda=10, dense G and res C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_17_19(for_inference=False, downblock_cls=ResBlockDown):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, downblock_cls=downblock_cls)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False,\n",
    "                              upblock_cls=DenseBlockUp)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_17(*args, **kwargs):\n",
    "    return create_learner_17_19(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_17()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr17_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17b: w/o activation after concat in G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_17b(*args, **kwargs):\n",
    "    learn = create_learner_17(*args, **kwargs)\n",
    "    for block in learn.model.generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_17b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr17b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 18 [TR 14 w/ dense G and C]: WGAN-GP lambda=10, dense G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18(*args, **kwargs):\n",
    "    return create_learner_17_19(downblock_cls=DenseBlockDown, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr18_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18b: w/o activation after concat in G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18b(*args, **kwargs):\n",
    "    learn = create_learner_18(*args, **kwargs)\n",
    "    for block in learn.model.generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(19, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr18b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18c: w/o activation after concat in G and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18c(*args, **kwargs):\n",
    "    learn = create_learner_18(*args, **kwargs)\n",
    "    for block in learn.model.generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "    for block in learn.model.critic:\n",
    "        if isinstance(block, DenseBlockDown):\n",
    "            block.act = nn.Identity()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18c()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18c2: lr={C:4e-4, G:1e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18c2(*args, **kwargs):\n",
    "    learn = create_learner_18c(*args, **kwargs)\n",
    "    learn.add_cb(GANDiscriminativeLR(mult_lr=4.))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18c2()\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c2_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18c3: lr={C:4e-4, G:1e-4} (18c2) until 8 epochs; lr={C:8e-5, G:2e-5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18c4: lr={C:4e-4, G:1e-4} (18c2) until 8 epochs; lr={C:2e-4, G:2e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18c4(*args, **kwargs):\n",
    "    learn = create_learner_18c(*args, **kwargs)\n",
    "    learn.add_cb(GANDiscriminativeLR(mult_lr=10.))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18c4()\n",
    "lr = 2e-5\n",
    "custom_load_model(learn, 'noise2img_tr18c2_8ep', base_path='./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c4_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18c5: lr={C:4e-4, G:1e-4} (18c2) until 6 epochs; then, lr={C:2e-4, G:2e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18c5(*args, **kwargs):\n",
    "    learn = create_learner_18c(*args, **kwargs)\n",
    "    learn.add_cb(GANDiscriminativeLR(mult_lr=10.))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18c5()\n",
    "lr = 2e-5\n",
    "custom_load_model(learn, 'noise2img_tr18c2_6ep', base_path='./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c5_8ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c5_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18c6: lr={C:2e-4, G:2e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18c6(*args, **kwargs):\n",
    "    learn = create_learner_18c(*args, **kwargs)\n",
    "    learn.add_cb(GANDiscriminativeLR(mult_lr=10.))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18c6()\n",
    "lr = 2e-5\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c6_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c6_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c6_18ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18c7: lr={C:2e-4, G:5e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_18c7(*args, **kwargs):\n",
    "    learn = create_learner_18c(*args, **kwargs)\n",
    "    learn.add_cb(GANDiscriminativeLR(mult_lr=4.))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_18c7()\n",
    "lr = 5e-5\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr18c7_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 19 [TR 14 w/ dense G and pseudoDense C]: WGAN-GP lambda=10, dense G and pseudo-dense C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_19(*args, **kwargs):\n",
    "    return create_learner_17_19(downblock_cls=PseudoDenseBlockDown, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_19()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr19_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19b: w/o activation after concat in G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_19b(*args, **kwargs):\n",
    "    learn = create_learner_19(*args, **kwargs)\n",
    "    for block in learn.model.generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_19b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr19b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19c: w/o activation after concat in G and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_19c(*args, **kwargs):\n",
    "    learn = create_learner_19(*args, **kwargs)\n",
    "    for block in learn.model.generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "    for block in learn.model.critic:\n",
    "        if isinstance(block, PseudoDenseBlockDown):\n",
    "            block.act = nn.Identity()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_19c()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr19c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(6, 5e-5)\n",
    "custom_save_model(learn, 'noise2img_tr19c_16ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(4, 2e-5)\n",
    "custom_save_model(learn, 'noise2img_tr19c_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, 2e-5)\n",
    "custom_save_model(learn, 'noise2img_tr19c_22ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 20 [TR 14 w/ 1 extra conv/block in C too]: WGAN-GP lambda=10, res G and C, SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_20(for_inference=False, id_up_conv_ks=3):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=1, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=id_up_conv_ks, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_20()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(learn.model.generator[1][2].weight,\n",
    "learn.model.generator[2].inner_path[0][2].weight,\n",
    "learn.model.generator[2].inner_path[1][2].weight,\n",
    "learn.model.generator[2].id_path[1][1].weight,\n",
    "learn.model.critic[2].inner_path[0][2].weight,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr20_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTUR C lr=4e-4; G lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_20b(*args, **kwargs): \n",
    "    learn = create_learner_20(*args, **kwargs)\n",
    "    learn.add_cb(GANDiscriminativeLR(mult_lr=4.))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_20b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 1e-4)\n",
    "custom_save_model(learn, 'noise2img_tr20b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 21 [TR 14 w/ ks=3 for up and down convs]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_21(for_inference=False, id_up_conv_ks=3):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=3, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=3, act_cls=nn.ReLU, bn_1st=False, output_padding=1)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=id_up_conv_ks, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_21()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr21_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21b: ks=3 only in downblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_21b(for_inference=False, id_up_conv_ks=3):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=3, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=id_up_conv_ks, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_21b()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr21b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 22 [TR 14 w/ conv2x2 as down id_path]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp, downsample id path with ks=2 instead of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_22(for_inference=False, id_up_conv_ks=3):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=2, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=id_up_conv_ks, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_22()\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr22_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 23: WGAN-GP lambda=10, semires G and C, SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with interp+conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_23(for_inference=False):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=True,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    critic = semires_critic(img_size, n_channels, down_op, act_cls=leakyReLU02,\n",
    "                            bn_1st=True)\n",
    "    up_op = InterpConvUpsamplingOp2d(act_cls=nn.ReLU, bn_1st=True)\n",
    "    generator = semires_generator(img_size, n_channels, up_op, bn_1st=True)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_23()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)\n",
    "custom_save_model(learn, 'noise2img_tr23_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 24 [TR 17b w/ 1 xtra conv/downblock]: WGAN-GP lambda=10, dense G and res C, SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_24(for_inference=False, downblock_cls=ResBlockDown):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=1, act_cls=leakyReLU02, \n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False,\n",
    "                              upblock_cls=DenseBlockUp)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_24()\n",
    "learn.add_cb(GANDiscriminativeLR(mult_lr=4.))\n",
    "lr = 1e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr24_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 25 [TR 17b w/ down convs ks=3, conv2x2 as down id path]: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_25(for_inference=False, downblock_cls=ResBlockDown):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=3, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=2, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02, \n",
    "                        bn_1st=False)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False,\n",
    "                              upblock_cls=DenseBlockUp)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_25()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(7, lr)\n",
    "custom_save_model(learn, 'noise2img_tr25_7ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_load_model(learn, 'noise2img_tr25_7ep', base_path='./models')\n",
    "learn.add_cb(GANDiscriminativeLR(mult_lr=4.))\n",
    "lr = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, lr)\n",
    "custom_save_model(learn, 'noise2img_tr25_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr25_12ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 26 [TR 17b w/ x2 features]: WGAN-GP lambda=10, dense G and res C (G a bit deeper, x2 ftrs both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_26(for_inference=False):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False,\n",
    "                              upblock_cls=DenseBlockUp, n_features=128)\n",
    "    for block in generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_26()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr26_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mean_weights(learn.model.generator, (nn.BatchNorm2d,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr26_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 27 [TR 26 w/ ConvLayer instead of ResBlock as extra]: WGAN-GP lambda=*, dense G and res C (G a bit deeper, x2 ftrs both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_27(for_inference=False, gp_w=10.):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False,\n",
    "                              upblock_cls=DenseBlockUp, n_features=128)\n",
    "    generator[5] = ConvLayer(128, 128, bn_1st=False)\n",
    "    critic[1] = ConvLayer(128, 128, bn_1st=False, act_cls=leakyReLU02)\n",
    "    for block in generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=gp_w))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_27()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27b: gp w = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_27b(*args, **kwargs):\n",
    "    return create_learner_27(gp_w=50., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_27b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27b_11ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "learn.fit(4, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27b_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27b_18ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27b_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(4, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27b_24ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27c: gp w = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_27c(*args, **kwargs):\n",
    "    return create_learner_27(gp_w=500., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_27c()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr27c_12ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 28 [TR 14 with RescaledResBlockUp/Down and coherent blocks]: WGAN-GP lambda=10, res G and C (G a bit deeper), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_28(for_inference=False):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=None, bn_1st=True,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=NormType.Batch)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=True, downblock_cls=RescaledResBlockDown)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=True)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=True,\n",
    "                              upblock_cls=RescaledResBlockUp)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_28()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr28_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28b: leave critic with traditional architecture, except for rescaling at the end of ResBlockDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_28b(for_inference=False):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, downblock_cls=RescaledResBlockDown)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=True)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=True,\n",
    "                              upblock_cls=RescaledResBlockUp)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_28b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr28b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 29 [TR 14 with x2 features]: WGAN-GP lambda=10, res G and C (G a bit deeper, x2 ftrs both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_29(for_inference=False, gp_w=10.):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False, \n",
    "                              n_features=128)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=gp_w))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_29()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr29_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29b: gp w=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_29b(*args, **kwargs):\n",
    "    return create_learner_29(gp_w=50., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_29b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr29b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29c: gp=50, ConvLayer instead of ResBlock as extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_29c(*args, **kwargs):\n",
    "    learn = create_learner_29(gp_w=50., *args, **kwargs)\n",
    "    learn.model.generator[5] = ConvLayer(128, 128, bn_1st=False)\n",
    "    add_sn(learn.model.generator[5])\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    learn.model.critic[1] = ConvLayer(128, 128, bn_1st=False, act_cls=leakyReLU02)\n",
    "    add_sn(learn.model.critic[1])\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_29c()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr29c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 30 [Tr27 adding missing SN]: WGAN-GP lambda=*, dense G and res C (G a bit deeper, x2 ftrs both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose+Id interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_30(for_inference=False, gp_w=10.):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op =  InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False,\n",
    "                              upblock_cls=DenseBlockUp, n_features=128)\n",
    "    generator[5] = ConvLayer(128, 128, bn_1st=False)\n",
    "    add_sn(generator[5])\n",
    "    critic[1] = ConvLayer(128, 128, bn_1st=False, act_cls=leakyReLU02)\n",
    "    add_sn(critic[1])\n",
    "    for block in generator:\n",
    "        if isinstance(block, DenseBlockUp):\n",
    "            block.act = nn.Identity()\n",
    "\n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=gp_w))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_30()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr30_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30b: gp w=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_30b(*args, **kwargs):\n",
    "    return create_learner_30(gp_w=50., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_30b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(9, lr)\n",
    "custom_save_model(learn, 'noise2img_tr30b_9ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "learn.fit(1, lr)\n",
    "custom_save_model(learn, 'noise2img_tr30b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr30b_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr30b_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr30b_25ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 31 [TR 11 w/ x2 features]: WGAN-GP lambda=10, res G and C (G a bit deeper, x2), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample with ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_31(for_inference=False, gp_w=10.):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConvHalfDownsamplingOp2d(ks=1, act_cls=None, padding=0, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = ConvX2UpsamplingOp2d(ks=1, act_cls=None, padding=0, output_padding=1)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False,\n",
    "                              n_features=128)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=10.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31b: gp w=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_31b(*args, **kwargs):\n",
    "    return create_learner_31(gp_w=50., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_31b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr31b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr31b_12ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 32 [TR 29 w/ concatpool as id down op]: WGAN-GP lambda=10, res G and C (G a bit deeper, x2 ftrs both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample: ConvTranspose+Id interp, downsample: Conv+Id ConcatPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_32(for_inference=False, add_down_id_conv=False, down_id_norm_type=None):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConcatPoolHalfDownsamplingOp2d(conv_ks=3, act_cls=None, norm_type=down_id_norm_type, \n",
    "                                                always_add_conv=add_down_id_conv)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False, \n",
    "                              n_features=128)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=50.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32a: w/o conv nor BN in id path of downblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_32()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(9, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32_9ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "learn.fit(1, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32b: w/ 3x3 conv and w/o BN in \"id\" path of downblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_32b(*args, **kwargs):\n",
    "    return create_learner_32(add_down_id_conv=True, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_32b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32c: w/ 3x3 conv and BN in \"id\" path of downblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_32c(*args, **kwargs):\n",
    "    return create_learner_32(add_down_id_conv=True, down_id_norm_type=NormType.Batch,\n",
    "                             *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_32c()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32d: w/o conv nor BN in id path of downblocks, ConvLayer instead of ResBlock as extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_32d(*args, **kwargs):\n",
    "    learn = create_learner_32(*args, **kwargs)\n",
    "    learn.model.generator[5] = ConvLayer(128, 128, bn_1st=False)\n",
    "    add_sn(learn.model.generator[5])\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    learn.model.critic[1] = ConvLayer(128, 128, bn_1st=False, act_cls=leakyReLU02)\n",
    "    add_sn(learn.model.critic[1])\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_32d()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32d_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32d_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, lr)\n",
    "custom_save_model(learn, 'noise2img_tr32d_18ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 33 [TR 32 w/ cond BN]: WGAN-GP lambda=10, res G and C (G a bit deeper, x2 ftrs both), SN+BN in G and C, 1 C/G iters, leaky as C act, upsample: ConvTranspose+Id interp, downsample: Conv+Id ConcatPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamRemover(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        return self.module(*args[:-1])\n",
    "    \n",
    "    \n",
    "class ParamRemoverUpsamplingOp2d(UpsamplingOperation2d):\n",
    "    def __init__(self, wrapped_up_op):\n",
    "        self.wrapped_up_op = wrapped_up_op\n",
    "        \n",
    "    def get_layer(self, in_ftrs:int=None, out_ftrs:int=None, **op_kwargs) -> nn.Module:\n",
    "        return ParamRemover(self.wrapped_up_op.get_layer(in_ftrs, out_ftrs, **op_kwargs))\n",
    "\n",
    "\n",
    "def create_learner_33(for_inference=False, noise_split_strategy=None, use_id_path_cond_bn=True):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    in_sz = 100\n",
    "    if noise_split_strategy is None:\n",
    "        noise_split_strategy = NoiseSplitEqualLeave1stOutStrategy()\n",
    "    n_noise_splits = CondResGenerator.calc_n_upblocks(img_size)\n",
    "    cond_sz = noise_split_strategy.calc_cond_sz(in_sz, n_noise_splits)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConcatPoolHalfDownsamplingOp2d(act_cls=None, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = CondConvX2UpsamplingOp2d(cond_sz, ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = (CondInterpConvUpsamplingOp2d(cond_sz, ks=3, act_cls=None) if use_id_path_cond_bn\n",
    "                else ParamRemoverUpsamplingOp2d(InterpConvUpsamplingOp2d(ks=3, act_cls=None)))\n",
    "    generator = CondResGenerator(img_size, n_channels, up_op, id_up_op, \n",
    "                                 noise_split_strategy, bn_1st=False, \n",
    "                                 in_sz=in_sz, n_features=128)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=50.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33a: with condBN in up id path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn = create_learner_33()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr33_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr33_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr33_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33b: with regular BN in up id path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_33b(*args, **kwargs):\n",
    "    return create_learner_33(use_id_path_cond_bn=False, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_33b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(8, lr)\n",
    "custom_save_model(learn, 'noise2img_tr33b_8ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33c: with regular BN in up id path, pass full noise vector to every condBN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_33c(*args, **kwargs):\n",
    "    return create_learner_33(use_id_path_cond_bn=False, \n",
    "                             noise_split_strategy=NoiseSplitDontSplitStrategy(),\n",
    "                             *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_33c()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, lr)\n",
    "custom_save_model(learn, 'noise2img_tr33c_8ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr33c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr33c_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 34 [TR 32 w/o BN in C]: WGAN-GP lambda=10, res G and C (G a bit deeper, x2 ftrs both), SN+BN in G, SN in C, 1 C/G iters, leaky as C act, upsample: ConvTranspose+Id interp, downsample: Conv+Id ConcatPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "\n",
    "def create_learner_34(for_inference=False, gp_w=50., down_op_act_cls=leakyReLU02, crit_iters_ratio=1,\n",
    "                      n_extra_convs_by_downblock=0):\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=down_op_act_cls, norm_type=None)\n",
    "    id_down_op = ConcatPoolHalfDownsamplingOp2d(conv_ks=3, act_cls=None, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=n_extra_convs_by_downblock, \n",
    "                        act_cls=leakyReLU02, n_features=128, norm_type=None, \n",
    "                        downblock_cls=partial(ResBlockDown, downsample_first=True))\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False, \n",
    "                              n_features=128)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        if gp_w > 1e-8:\n",
    "            cbs.append(GANGPCallback(plambda=gp_w))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=crit_iters_ratio, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34b: gp w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34b(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=1., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34c: gp w = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34c(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=0.1, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34c()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34d: gp w = 1, C iters ratio = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34d(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=1., crit_iters_ratio=5, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34d()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34d_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34e: gp w = 1, w/o act in down op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34e(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=1., down_op_act_cls=None, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34e()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34e_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34f: gp w = 0.1, w/o act in down op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34f(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=0.1, down_op_act_cls=None, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34f()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34f_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34g: no gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34g(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=0., down_op_act_cls=None, \n",
    "                             *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34g()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34g_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34h: gp w=0.1, 1 extra conv by downblock, w/o last act in downblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34h(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=0.1, n_extra_convs_by_downblock=1,\n",
    "                             *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34h()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34h_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34h_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34i: gp w=10, 1 extra conv by downblock, w/o last act in downblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_34i(*args, **kwargs):\n",
    "    return create_learner_34(gp_w=10., n_extra_convs_by_downblock=1,\n",
    "                             *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_34i()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr34i_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 35 [TR 32 w/ R1 GP]: WGAN-R1GP, res G and C (G a bit deeper, x2 ftrs both), SN+BN in G, SN in C, 1 C/G iters, leaky as C act, upsample: ConvTranspose+Id interp, downsample: Conv+Id ConcatPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_35(for_inference=False, gp_w=10.):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConcatPoolHalfDownsamplingOp2d(conv_ks=3, act_cls=None, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False, \n",
    "                              n_features=128)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(R1GANGPCallback(weight=gp_w))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35a: gp w = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn = create_learner_35()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr35_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr35_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35b: gp w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_35b(*args, **kwargs):\n",
    "    return create_learner_35(gp_w=1., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn = create_learner_35b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)\n",
    "custom_save_model(learn, 'noise2img_tr35b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr35b_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr35b_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, lr)\n",
    "custom_save_model(learn, 'noise2img_tr35b_23ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35c: gp w = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_35c(*args, **kwargs):\n",
    "    return create_learner_35(gp_w=0.1, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_35c()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr35c_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 36 [TR 32 w/ NSGAN+R1 GP]: NSGAN-R1GP w=10, res G and C (G a bit deeper, x2 ftrs both), SN+BN in G, SN in C, 1 C/G iters, leaky as C act, upsample: ConvTranspose+Id interp, downsample: Conv+Id ConcatPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_36(for_inference=False, gp_w=10.):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConcatPoolHalfDownsamplingOp2d(conv_ks=3, act_cls=None, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128, flatten_full=True)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = res_generator(img_size, n_channels, up_op, id_up_op, bn_1st=False, \n",
    "                              n_features=128)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(R1GANGPCallback(weight=gp_w))\n",
    "    def gen_loss_func(*args): return 0\n",
    "    crit_loss_func = nn.BCEWithLogitsLoss()\n",
    "    loss_G, loss_C = gan_loss_from_func(gen_loss_func, crit_loss_func)\n",
    "    \n",
    "    learn = GANLearner(dls, generator, critic, loss_G, loss_C,\n",
    "                       opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                       cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1),\n",
    "                       switch_eval=False)\n",
    "    # TODO: watchout with switch_eval; wgan passes False by default; but in __init__ default is True.\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36a: gp w = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_36()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit(1, lr)\n",
    "custom_save_model(learn, 'noise2img_tr36_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36b: gp w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_36b(*args, **kwargs):\n",
    "    return create_learner_36(gp_w=1., *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn = create_learner_36b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr36b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr36b_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr36b_20ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit(3, lr)\n",
    "custom_save_model(learn, 'noise2img_tr36b_23ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 37 [TR 32 w/ skip G]: WGAN-GP w=50, skip-res G and res C (G a bit deeper, x2 ftrs both), SN+BN in G, SN in C, 1 C/G iters, leaky as C act, upsample: ConvTranspose+Id interp, downsample: Conv+Id ConcatPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_37(for_inference=False, skip2rgb_ks=3, skip_act_cls=nn.Tanh):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConcatPoolHalfDownsamplingOp2d(conv_ks=3, act_cls=None, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = SkipGenerator(img_size, n_channels, up_op, id_up_op, bn_1st=False, \n",
    "                              n_features=128, skip2rgb_ks=skip2rgb_ks,\n",
    "                              skip_act_cls=skip_act_cls)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(GANGPCallback(plambda=50.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37a: Skip to rgb conv ks = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_37()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr37_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, lr)\n",
    "custom_save_model(learn, 'noise2img_tr37_15ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 37a2: skip act = ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_37a2(*args, **kwargs):\n",
    "    return create_learner_37(skip_act_cls=nn.ReLU, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37b: Skip to rgb conv ks = 1, skip act = ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_37b(*args, **kwargs):\n",
    "    return create_learner_37(skip2rgb_ks=1, skip_act_cls=nn.ReLU, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner_37b()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1, lr)\n",
    "custom_save_model(learn, 'noise2img_tr37b_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR 38 [TR 37 w/ R1-GP]: WGAN-R1GP w=1, skip-res G and res C (G a bit deeper, x2 ftrs both), SN+BN in G, SN in C, 1 C/G iters, leaky as C act, upsample: ConvTranspose+Id interp, downsample: Conv+Id ConcatPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner_38(for_inference=False, skip2rgb_ks=3, skip_act_cls=nn.ReLU):\n",
    "    leakyReLU02 = partial(nn.LeakyReLU, negative_slope=0.2)\n",
    "    down_op = ConvHalfDownsamplingOp2d(ks=4, act_cls=leakyReLU02, bn_1st=False,\n",
    "                                       norm_type=NormType.Batch)\n",
    "    id_down_op = ConcatPoolHalfDownsamplingOp2d(conv_ks=3, act_cls=None, norm_type=None)\n",
    "    critic = res_critic(img_size, n_channels, down_op, id_down_op,\n",
    "                        n_extra_convs_by_res_block=0, act_cls=leakyReLU02,\n",
    "                        bn_1st=False, n_features=128)\n",
    "    up_op = ConvX2UpsamplingOp2d(ks=4, act_cls=nn.ReLU, bn_1st=False)\n",
    "    id_up_op = InterpConvUpsamplingOp2d(ks=3, act_cls=None)\n",
    "    generator = SkipGenerator(img_size, n_channels, up_op, id_up_op, bn_1st=False, \n",
    "                              n_features=128, skip2rgb_ks=skip2rgb_ks,\n",
    "                              skip_act_cls=skip_act_cls)\n",
    "    \n",
    "    cbs = []\n",
    "    if not for_inference:\n",
    "        cbs.append(R1GANGPCallback(weight=1.))\n",
    "    learn = GANLearner.wgan(dls, generator, critic, opt_func=partial(Adam, mom=0., sqr_mom=0.99, wd=0.),\n",
    "                            clip=None, cbs=cbs, switcher=FixedGANSwitcher(n_crit=1, n_gen=1))\n",
    "    learn.recorder.train_metrics=True\n",
    "    learn.recorder.valid_metrics=False\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn = create_learner_38()\n",
    "lr = 2e-4\n",
    "(every_conv_has_sn(learn.model.critic), every_conv_has_sn(learn.model.generator),\n",
    "learn.model.generator, learn.model.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr)\n",
    "custom_save_model(learn, 'noise2img_tr38_10ep', base_path='.')\n",
    "learn.show_results(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('./models/noise2img_tr35b_23ep.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_fid_samples_path = Path('./fid_samples')\n",
    "n_fid_imgs = 10000\n",
    "\n",
    "def download_pytorch_fid_calculator():        \n",
    "    #!git clone https://github.com/mseitzer/pytorch-fid.git\n",
    "    !pip install pytorch-fid\n",
    "\n",
    "def create_fid_dirs(base_fid_samples_path):\n",
    "    base_fid_samples_path.mkdir()\n",
    "    (base_fid_samples_path/'fake').mkdir()\n",
    "    (base_fid_samples_path/'real').mkdir()\n",
    "        \n",
    "def save_real_imgs(dls, n_imgs=10000, use_input_ds=False):\n",
    "    n_imgs_left = n_imgs\n",
    "    while n_imgs_left > 0:\n",
    "        b = dls.one_batch()\n",
    "        bs = b[1].size()[0]\n",
    "        dec_b = dls.decode_batch(b, max_n=bs)\n",
    "        for i in range(bs):\n",
    "            if n_imgs_left == 0: break\n",
    "            tuple_idx = 0 if use_input_ds else 1\n",
    "            img_t = dec_b[i][tuple_idx]\n",
    "            img = PILImage.create(img_t)\n",
    "            img_idx = n_imgs_left-1\n",
    "            img.save(base_fid_samples_path/f'real/{img_idx}.jpg')\n",
    "            #if n_imgs_left % 1000 == 0: print(\"saved \" + str(img_idx))\n",
    "            n_imgs_left -= 1\n",
    "\n",
    "def save_fake_imgs(learner, n_imgs=10000, **predict_n_kwargs):\n",
    "    base_path = base_fid_samples_path\n",
    "    preds_batch = predict_n(learner, n_imgs, **predict_n_kwargs)\n",
    "    for i, (inp, img) in enumerate(preds_batch):\n",
    "        PILImage.create(img).save(base_path/f'fake/{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -R $base_fid_samples_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "download_pytorch_fid_calculator()\n",
    "create_fid_dirs(base_fid_samples_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(builders, n_epochs, base_path='/kaggle/input/new-face2anime-weights'):\n",
    "    assert is_iterable(builders) or is_iterable(n_epochs)\n",
    "    if not is_iterable(builders): \n",
    "        builders = [builders] * len(list(n_epochs))\n",
    "    if not is_iterable(n_epochs): \n",
    "        n_epochs = [n_epochs] * len(list(builders))\n",
    "    for builder, n_ep in zip(builders, n_epochs):\n",
    "        model_id = builder.__name__.split('_')[-1]\n",
    "        learner = builder(for_inference=True)\n",
    "        custom_load_model(learner, f'noise2img_tr{model_id}_{n_ep}ep', with_opt=False,\n",
    "                          base_path=base_path)\n",
    "        save_fake_imgs(learner, n_imgs=n_fid_imgs)\n",
    "        print(f'---- {model_id}, after {n_ep} epochs ----')\n",
    "        !python -m pytorch_fid {base_fid_samples_path/'fake'} {base_fid_samples_path/'real'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_real_imgs(dls, n_fid_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "eval_models(create_learner_36b, list(range(1, 11)), base_path='./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PILImage.create(base_fid_samples_path/'real/1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Loss func | GP w | Crit arch | Gen Arch | Up op | Down op | Crit norm | Gen norm | Crit act | C/G iters | Bs |\n",
    "| : | : | : | : | : | : | : | : | : | : | : | : |\n",
    "| 1 | WGAN-GP | 10 | basic | basic | ConvTr | Conv | SN+BN | SN+BN | ReLU | 5 | 64 |\n",
    "| 2 | WGAN-GP | 0.1| basic | basic | ConvTr | Conv | SN+BN | SN+BN | ReLU | 5 | 64 |\n",
    "| 3 | WGAN-GP | 10 | basic | basic | ConvTr | Conv | SN+BN | SN+BN | LeakyReLU | 5 | 64 |\n",
    "| 4 | WGAN-GP | 100 | basic | basic | ConvTr | Conv | SN+BN | SN+BN | LeakyReLU | 5 | 64 |\n",
    "| 5 | WGAN-GP | 10 | basic | basic | ConvTr | Conv | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 6 | WGAN-GP | 10 | basic | basic |Interp+conv| Conv | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 7 | WGAN-GP | 10 | basic | basic |PixelShuffle| Conv | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 8 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-BN-R/C-BN, Id:CTR1x1-BN | C-BN-LR, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 9 | WGAN-GP | 10 | res 1xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-BN-R/C-BN, Id:CTR1x1-BN | C-BN-LR/C-BN-LR, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 10 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-BN-R/C-BN, Id:CTR1x1-BN | C-BN, Id:C1x1-BN | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 10b| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-BN-R/C-BN, Id:CTR1x1-BN | C-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 11 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 11b| WGAN-GP | 10 | res 0xtra/b; 1xtra l | res 1xtra/b; 1xtra l | CTR-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 12 | WGAN-GP | 10 | res 1xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 12b| WGAN-GP | 10 | res 1xtra/b; 1xtra l | res 1xtra/b; 1xtra l | CTR-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 13 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:AP-C | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 13b| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:AP-C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 14 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 14b| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 15 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | INT-C-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 15b| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | INT-C1x1-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 15c| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | INT-C-R-BN/C-R-BN, Id:CTR1x1-R-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 15d| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | INT-C-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 16 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | INT-C-R-BN/C-R-BN, Id:INT-C1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 16b| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | INT-C-R-BN/C-R-BN, Id:INT-C1x1-R-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 17 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | den 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 18 | WGAN-GP | 10 | den 0xtra/b; 1xtra res | den 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 19 | WGAN-GP | 10 | pden 0xtra/b; 1xtra res | den 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 20 | WGAN-GP | 10 | res 1xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN/C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 21 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR3x3-R-BN/C-R-BN, Id:INT-C-BN | C3x3-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 21b| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C3x3-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 22 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C2x2 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 23 | WGAN-GP | 10 | semires 1xtra res | semires 1xtra res | INT-C-BN-R | C-BN-LR | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 24 | WGAN-GP | 10 | res 1xtra/b; 1xtra res | den 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN/C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 25 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | den 1xtra/b; 1xtra res | CTR-R-BN/C-R-BN, Id:INT-C-BN | C3x3-LR-BN, Id:C2x2 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 26 | WGAN-GP | 10 | res 0xtra/b; 1xtra res, x2ftrs | den 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 27 | WGAN-GP | 10 | res 0xtra/b; 1xtra l; x2ftrs | den 1xtra/b; 1xtra l; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 27b| WGAN-GP | 50 | res 0xtra/b; 1xtra l; x2ftrs | den 1xtra/b; 1xtra l; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 27c| WGAN-GP | 500| res 0xtra/b; 1xtra l; x2ftrs | den 1xtra/b; 1xtra l; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 28 | WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-BN-R/C-BN, Id:INT-C-BN | C-BN, Id:C1x1-BN | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 28b| WGAN-GP | 10 | res 0xtra/b; 1xtra res | res 1xtra/b; 1xtra res | CTR-BN-R/C-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 29 | WGAN-GP | 10 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 29b| WGAN-GP | 50 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 29c| WGAN-GP | 50 | res 0xtra/b; 1xtra l; x2ftrs | res 1xtra/b; 1xtra l; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 30 | WGAN-GP | 10 | res 0xtra/b; 1xtra l; x2ftrs | den 1xtra/b; 1xtra l; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 30b| WGAN-GP | 50 | res 0xtra/b; 1xtra l; x2ftrs | den 1xtra/b; 1xtra l; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 31b| WGAN-GP | 50 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:CTR1x1-BN | C-LR-BN, Id:C1x1 | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 32 | WGAN-GP | 50 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 32d| WGAN-GP | 50 | res 0xtra/b; 1xtra l; x2ftrs | res 1xtra/b; 1xtra l; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 33 | WGAN-GP | 50 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-CBN/C-R-CBN, Id:INT-C-CBN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 33c| WGAN-GP | 50 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-CBN/C-R-CBN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 34 | WGAN-GP | 50 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR, Id:ConcatPool | SN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 34c| WGAN-GP | 0.1| res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR, Id:ConcatPool | SN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 34f| WGAN-GP | 0.1| res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C, Id:ConcatPool | SN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 34g| WGAN-GP | 0  | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR, Id:ConcatPool | SN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 35 |WGAN-R1GP| 10 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 35b|WGAN-R1GP|  1 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 35c|WGAN-R1GP| 0.1| res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 36 |NSGAN-R1GP| 10| res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 36b|NSGAN-R1GP| 1 | res 0xtra/b; 1xtra res; x2ftrs | res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 37 | WGAN-GP | 50 | res 0xtra/b; 1xtra res; x2ftrs | skip-res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |\n",
    "| 38 |WGAN-R1GP| 10 | res 0xtra/b; 1xtra res; x2ftrs | skip-res 1xtra/b; 1xtra res; x2ftrs | CTR-R-BN/C-R-BN, Id:INT-C-BN | C-LR-BN, Id:ConcatPool | SN+BN | SN+BN | LeakyReLU | 1 | 64 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results after 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model ID | Final FID | Min FID (1,5,8,10) | Overall min FID |\n",
    "| : | : | : | : |\n",
    "| 1 | 20.2 | 20.2 | ? |\n",
    "| 2 | 26.3 | 25.8 | ? |\n",
    "| 3 | 27.1 | 27.1 | ? |\n",
    "| 4 | 33.6 | 33.6 | ? |\n",
    "| 5 | 22.0 | 16.4 | ? |\n",
    "| 5b| 13.4 | 13.4 | ? |\n",
    "| 6 | 19.6 | 14.8 | ? |\n",
    "| 7 | 27.2 | 22.6 | ? |\n",
    "| 8 | 20.1 | 20.1 | ? |\n",
    "| 9 |118.8 | 26.7 | ? |\n",
    "| 10 | 39.4 | 27.4 | ? |\n",
    "| 11 | 17.4 | 16.7 | ? |\n",
    "| 11b| 15.0 | 15.0 | ? |\n",
    "| 11c| 14.8 | 14.8 | ? |\n",
    "| 12b| 19.6 | 19.6 | ? |\n",
    "| 13 | 20.9 | 20.3 | ? |\n",
    "| 13b| 29.3 | 18.1 | ? |\n",
    "| 14 | 13.0 | 12.8 | ? |\n",
    "| 14b| 18.8 | 16.5 | ? |\n",
    "| 15 | 70.3 | 22.4 | ? |\n",
    "| 15b| BAD | BAD | ? |\n",
    "| 15c| 35.3 | 35.3 | ? |\n",
    "| 15d| 40.2 | 21.4| ? |\n",
    "| 16 | 29.9 | 18.1 | ? |\n",
    "| 16b| 21.5 | 20.8 | ? |\n",
    "| 17 | 15.4 | 15.4 | ? |\n",
    "| 17b| 11.8 | 11.8 | 11.8 |\n",
    "| 18 | 18.4 | 18.4 | ? |\n",
    "| 18c| 18.1 | 16.2 | ? |\n",
    "| 19 | 14.0 | 13.2 | ? |\n",
    "| 19c| 12.8 | 12.8 | ? |\n",
    "| 20 | 16.9 | 15.3 | ? |\n",
    "| 21 | 12.6 | 12.6 | ? |\n",
    "| 21b| 13.1 | 13.1 | ? |\n",
    "| 22 | 13.1 | 13.1 | ? |\n",
    "| 23 | 19.2 | 16.9 | 16.2 |\n",
    "| 25 | 22.1 | 18.4 | 15.7 |\n",
    "| 26 | 15.6 | 13.9 | 13.7 |\n",
    "| 27 | 12.2 | 12.2 | 12.1 |\n",
    "| 27b| 11.4 | 11.4 | 11.4 |\n",
    "| 27c| 11.2 | 11.2 | 11.2 |\n",
    "| 28 | 16.2 | 16.2 | 14.5 |\n",
    "| 28b| 14.3 | 12.5 | 12.5 |\n",
    "| 29 | 11.7 | 11.7 | 11.7 |\n",
    "| 29b|  9.1 |  9.1 |  9.1 |\n",
    "| 29c|  8.9 |  8.9 |  8.9 |\n",
    "| 30 | 14.4 | 12.2 | 12.2 |\n",
    "| 30b| 13.5 | 13.4 |  9.4 |\n",
    "| 31b| 16.3 | 16.3 | 14.9 |\n",
    "| 32 |  8.9 |  8.9 |  8.2 |\n",
    "| 32b| 14.5 |  9.7 |  9.7 |\n",
    "| 32c| 12.6 | 12.6 | 11.3 |\n",
    "| 32d| 11.0 | 11.0 |  9.9 |\n",
    "| 33 |  9.1 |  9.1 |  9.1 |\n",
    "| 33b| 21.6 |  9.9 |  9.7 |\n",
    "| 33c|  9.7 |  8.5 |  8.5 |\n",
    "| 34c| 15.3 | 15.3 | 15.3 |\n",
    "|\\*34f| 16.2| 16.2 | 14.4 |\n",
    "| 34g| 15.0 | 14.7 | 11.9 |\n",
    "| 35 |  9.3 |  9.3 |  9.3 |\n",
    "| 35b|  8.5 |  8.5 |  8.5 |\n",
    "| 36 | 12.0 | 12.0 | 12.0 |\n",
    "| 36b|  9.0 |  9.0 |  9.0 |\n",
    "| 37 | 11.4 |  9.8 |  9.8 |\n",
    "|37a2| 10.5 |  9.9 |  9.9 |\n",
    "| 37b| 14.7 | 14.7 | 13.9 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* 3rd column shows the min FID between checkpoints at epochs 1, 5, 8 and 10.\n",
    "* 4th column shows the min FID between checkpoints at every epoch between 1 and 10, only for the models for which they were recorded.\n",
    "\n",
    "Tr13 looks more appealing than what FID suggests.\n",
    "Tr34f was only trained 8 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "epochs = [1, 5, 8, 10]\n",
    "fids_tr1 = [94.0, 30.9, 20.5,  20.2]\n",
    "fids_tr2 = [100.2, 27.1, 25.8, 26.3]\n",
    "fids_tr3 = [119.7, 48.4, 28.5, 27.1]\n",
    "fids_tr4 = [106.7, 34.4, 105.7, 33.6]\n",
    "fids_tr5 = [63.7, 19.7, 16.4, 22.0]\n",
    "fids_tr5b = [63.7, 19.7, 16.4, 13.4]\n",
    "fids_tr6 = [44.5, 20.6, 14.8, 19.6]\n",
    "fids_tr7 = [67.4, 29.4, 22.6, 27.2]\n",
    "fids_tr8 = [69.8, 23.8, 22.3, 20.1]\n",
    "fids_tr9 = [70.6, 26.7, 27.3, 118.8]\n",
    "fids_tr10 = [81.6, 34.6, 27.4, 39.4]\n",
    "# Still with bn zero in up/down blocks\n",
    "fids_tr10b = [280.8, 38.4, 33.9, 30.8]\n",
    "fids_tr11 = [73.5, 24.2, 16.7, 17.4]\n",
    "fids_tr11b = [64.1, 20.7, 22.1, 15.0]\n",
    "fids_tr11c = [61.1, 22.0, 21.4, 14.8]\n",
    "fids_tr12b = [72.7, 24.8, 20.9, 19.6]\n",
    "fids_tr13 = [68.9, 23.7, 20.3, 20.9]\n",
    "# Not sure of this result.\n",
    "fids_tr13b = [64.2, 20.5, 18.1, 29.3]\n",
    "# At 10 epochs it has better quality but less diversity\n",
    "fids_tr14 = [38.9, 16.0, 12.8, 13.0] \n",
    "# Going on with tr14:\n",
    "# 11-20:          [12.2, 13.0, 14.9, 12.9, 11.7, 14.9, 14.0, 18.1, 11.3, 12.3]\n",
    "# 11-20(lr=5e-5): [ 9.8,  9.7,  9.8,  9.3, 10.4,  9.8,  9.9, 11.4, 10.6,  9.8]\n",
    "# 15-20(lr=1e-5):                          [9.7,  9.6,  9.9,  9.8,  9.4,  9.6]\n",
    "# 14a2 is 14 with lr=(C:4e-4, G:1e-4)\n",
    "fids_tr14a2 = [26.7, 14.0, 11.7, 12.4] # [3, 6, 7, 9] -> [21.8, 12.2, 16.5, 16.0]\n",
    "# 9-15(lr=(C:2e-4, G:5e-5)): [11.6, 50.1, 51.3, 10.5, 10.7, 11.8, 12.5]\n",
    "# 9-15(lr=(C:1e-4, G:2.5e-5)): [9.8, 9.6, 10.1, 12.4, 10.2, 18.6, 11.4]\n",
    "# 9-12(lr=(C:1e-4, G:1e-5)): [10.1, 11.4, 11.6, 53.3]\n",
    "# 9-20(lr=(C:4e-5, G:1e-5)): [18.6,  9.4,  9.6,  9.1,  ?,    ?,    9.8, 20.1, 9.0, 10.0, 10.0, 9.9]\n",
    "  # 13-17(lr=1e-5):                                  [10.6,  9.4,  9.7,  9.1,10.0] \n",
    "  # 13-18(lr=(C:1.2e-5, G:3e-6)):                    [ 9.6,  9.9,  9.8,  9.0, 9.7,  9.4]\n",
    "    \n",
    "fids_tr14b = [43.9, 16.5, 16.9, 18.8]\n",
    "# Mode collapse\n",
    "fids_tr15 = [59.2, 27.5, 22.4, 70.3]\n",
    "fids_tr15c = [89.1, 42.9, 35.3, 35.3]\n",
    "fids_tr15d = [46.1, 21.4, 52.1, 40.2]\n",
    "fids_tr16 = [31.9, 18.1, 20.0, 29.9]\n",
    "fids_tr16b = [35.3, 20.8, 24.3, 21.5]\n",
    "fids_tr17 = [40.2, 18.0, 17.1, 15.4]\n",
    "fids_tr17b = [48.7, 16.4, 15.8, 11.8] # [6, 7, 9] -> [13.7, 15.1, 15.8]\n",
    "# 11-14:          [12.8, 12.2, 12.6, 15.1]\n",
    "# 11-18 (lr=5e-5): [9.1,  9.6,  9.7,  9.4,  9.7,  9.9, 10.0,  9.6]\n",
    "# 12-20 (lr=2e-5):       [9.20, 9.16, 9.31, 9.18, 8.68, 8.79, 9.13, 9.17, 9.21]\n",
    "fids_tr17c = [65.6, 18.4] # 3, 6, 7 -> [26.5, 18.0, 19.4]\n",
    "# 8-14 (lr=5e5):  [13.5, 13.0, 12.9, 14.4, 13.7, 14.3, 13.7]\n",
    "\n",
    "fids_tr18 = [50.3, 19.0, 21.0, 18.4]\n",
    "fids_tr18b = [45.7, 26.0, 48.3, 87.6]\n",
    "fids_tr18c = [43.8, 17.9, 16.2, 18.1]\n",
    "# 18c2 is 18c with TTUR(4e-4, 1e-4)\n",
    "fids_tr18c2 = [27.2, 16.4, 11.9, 16.6] # [6, 7, 9] -> [14.1, 15.5, 16.9]\n",
    "# 18c3: With TTUR(8e-5, 2e-5) after epoch 8, [9, 10] -> [27.7, 31.1]\n",
    "# 18c4: With TTUR(2e-4, 2e-5) after epoch 8, [9, 10] -> [12.5, 55.1]\n",
    "# 18c5: With TTUR(2e-4, 2e-5) after epoch 6, [7, 8] -> [13.0, 17.4]\n",
    "# 1, 3, 5, 6, 7, ..., 15\n",
    "#18c6: 36.9, 22.2, 24.1, 15.9, 18.5, 18.0, 15.2, 15.6, 26.7, 19.6, 15.5, 11.9, collapse\n",
    "# 18c7 is 18c with TTUR(2e-4, 5e-5)\n",
    "fids_18c7 = [35.2, 19.9, 16.6, 18.9] # [3, 6, 7, 9] -> [21.4, 19.5, 21.7, 20.7]\n",
    "\n",
    "fids_tr19 = [40.7, 17.8, 13.2, 14.0]\n",
    "fids_tr19c = [51.5, 18.0, 16.7, 12.8] \n",
    "# 11-16(lr=5e-5): [10.6, 10.2, 10.1, 10.8, 9.9, 10.5]\n",
    "# 17-22 (lr=2e-5): [9.4, 11.1, 9.8, 9.3, 9.7, 9.4]\n",
    "\n",
    "fids_tr20 = [41.9, 17.2, 15.3, 16.9]\n",
    "# 20b is 20 with TTUR(4e-4, 1e-4)\n",
    "fids_tr20b = [25.8, 11.8, 13.1, 17.4]\n",
    "fids_tr21 = [49.8, 21.5, 13.1, 12.6]\n",
    "fids_tr21b = [43.1, 18.9, 19.2, 13.1] \n",
    "# 21b Following with TTUR(4e-4, 1e-4)... 11ep: 11.1; 15ep: 10.4\n",
    "fids_tr22 = [35.2, 15.2, 13.5, 13.05]\n",
    "fids_tr23 = [40.4, 81.6, 16.9, 19.2] # 3, 6, 7, 9 -> [25.7, 21.3, 16.2, 32.2]\n",
    "# 23b is 23 with TTUR(2e-4, 5e-5)\n",
    "fids_tr23b = [36.2, 21.7, 24.2, 56.0] # 3, 6, 7, 9 ->[30.5, 23.8, 39.0, 22.6]\n",
    "# TTUR(4e-4, 1e-4) since the beginning\n",
    "fids_tr24 = [31.4, 16.0, 16.8, 21.0] # 3, 7, 9 -> [20.1, 21.1, 16.0]\n",
    "# 6-10 (lr=(1e-4, 2.5e-5)): [12.1, 13.8, 19.0, 14.4, 14.3]\n",
    "fids_tr25 = [50.3, 27.3, 18.4, 22.1] # 3, 6, 7, 9 -> [28.8, 18.3, 16.4, 15.7]\n",
    "# 8-10 (lr=5e-5): [13.0, 13.6, 13.8]\n",
    "# 8-12 (lr=(2e-4, 5e-5)): [18.3, 21.7, 13.9, 16.7, 16.3]\n",
    "fids_tr26 = [23.8, 13.9, 14.0, 15.6]\n",
    "# All 1-10: [23.8, 16.7, 15.2, 14.7, 13.9, 19.2, 15.5, 14.0, 13.7, 15.6]\n",
    "# 6-10 (lr=1e-4):                         [11.9, 11.5, 14.5, 47.9, 52.9]\n",
    "# 7-16 (lr=5e-5):                               [11.5, 59.2, 162.6, 37.7, 24.2, 19.2, 19.8, 14.6, 25.6, 15.3]\n",
    "# 3-6 (lr=5e-5):        [13.3, 11.7, 13.0, 11.9]\n",
    "# 3-10 (lr=1e-5):       [13.8, 12.0, 11.6, 12.2, 11.9, 10.9, 11.7, 11.3]\n",
    "#Alllr=5e-4:[25.1, 15.9, 18.4, 15.4, 14.0, 16.9, 11.9, 21.0, 13.4, 21.8, 15.6, 12.9]\n",
    "fids_tr27 = [34.1, 12.3, 16.0, 12.2]\n",
    "# All:      [34.1, 19.6, 14.6, 12.7, 12.3, 16.1, 12.5, 16.0, 12.1, 12.2]\n",
    "fids_tr27b = [38.0, 13.7, 12.3, 11.4]\n",
    "# All:      [38.0, 19.7, 18.4, 15.9, 13.7, 12.6, 15.1, 12.3, 11.4, 11.4, 9.9, 10.4, 10.7, 11.1, 11.2]\n",
    "# Epoch 15 has some imgs with high realism despite not being top FID\n",
    "# 12-20(lr=5e-5, start:9.9): [7.8, 8.7, 7.8, 9.1, 8.2, 7.7, 7.3, 8.2, 8.1]\n",
    "# 19-24 (lr=2e-5, start:7.3): [7.55, 7.43, 8.30, 8.48, 8.03, 8.07]\n",
    "fids_tr27c = [54.4, 21.1, 14.6, 11.2]\n",
    "# All:      [54.4, 31.0, 25.0, 21.0, 21.1, 17.3, 13.7, 14.6, 13.0, 11.2, 11.8, 11.9]\n",
    "fids_tr28 = [47.8, 19.2, 17.4, 16.2]\n",
    "# All:      [47.8, 24.4, 21.9, 17.4, 19.2, 18.3, 14.5, 17.4, 15.3, 16.2]\n",
    "fids_tr28b = [46.6, 15.4, 12.5, 14.3]\n",
    "# All:      [46.6, 24.9, 21.1, 16.3, 15.4, 16.5, 14.2, 12.5, 16.8, 14.3]\n",
    "fids_tr29 = [22.4, 12.1, 13.2, 11.7]\n",
    "# All:      [22.4, 15.0, 12.2, 12.9, 12.1, 12.7, 16.4, 13.2, 12.0, 11.7]\n",
    "fids_tr29b = [27.4, 11.3, 15.2, 9.1]\n",
    "# All:      [27.4, 17.5, 13.0, 12.9, 11.3, 13.9,  9.8, 15.2, 11.0,  9.1, 10.3, 9.3, 11.5, 8.7, 11.1, 13.6, 9.9, 9.1, 10.1, 8.6] \n",
    "# lr=2e-4 collapses after epoch 20\n",
    "# 21- (lr=5e-5, start: 8.6): [7.8, 6.9, 7.0, 7.1, 7.3, 7.1]\n",
    "# 27- (lr=1e-5, start: 7.1): [7.3, 18.5, 12.5, 7.7, 7.0, 7.2]\n",
    "# 14- (lr=5e-5: start: 8.7):\n",
    "fids_tr29c = [29.8, 13.8, 10.1, 8.9]\n",
    "# All: [29.8, 21.9, 15.6, 13.6, 13.8, 10.7, 10.4, 10.1, 10.5, 8.9, 9.3, 9.1, 8.4, 10.1, 7.8, 8.1, 8.5, 8.2, 8.0, 7.7, 9.2]\n",
    "# 21-25(lr=1e-4, start: 7.7): [7.8, 7.1, 7.3, 6.9, 7.8]\n",
    "# 25-31(lr=5e-5, start: 6.9): [6.44, 6.38, 6.39, 7.4, 7.1, 6.7, 11.1]\n",
    "# 28- (lr=2e-5, start: 6.39): [6.26, 6.73, 6.83, 6.85]\n",
    "# 29- (lr=1e-5, start: 6.26): [6.04, 6.45, 6.43]\n",
    "# 29c2 is 29c with bs=128\n",
    "fids_tr29c2 = [37.3, 12.4, 9.9, 8.3]\n",
    "# All: [37.3, 27.1, 16.6, 12.5, 12.4, 10.1, 12.1, 9.9, 8.9, 8.3 (10ep), 9.4, 9.0, 8.3, 10.2, 8.8, 8.0, 8.4, 9.1, 7.7, 7.8, 8.1, 7.6, 9.6, 9.4, 8.5]\n",
    "# 20-23(lr=1e-4, start: 7.7): [6.9, 7.7, 7.1, 6.8]\n",
    "# 24- (lr=5e-5, start: 6.8): [6.6, 6.7, 6.3, 7.4]\n",
    "# 29-32(lr=2e-5, start: 7.4): [6.3, 6.5, 6.5, 6.6]\n",
    "# The epoch 31 of 2e-5 looks better than what FID tells\n",
    "\n",
    "fids_tr30 = [33.4, 13.6, 12.2, 14.4]\n",
    "# All:      [33.4, 18.1, 16.0, 13.5, 13.6, 12.2, 13.8, 12.2, 12.9, 14.4]\n",
    "fids_tr30b = [33.5, 13.4, 14.1, 13.5]\n",
    "# All:      [33.5, 24.2, 15.7, 18.0, 13.4, 12.4, 11.4, 14.1, 9.4, 13.5, 10.3, 10.0, 10.2, 10.7, 10.0, 10.3, 11.8]\n",
    "# 10-x(lr=5e-5, start: 9.4): [7.8, 9.6, 8.2, 8.0, 9.4, 7.8, 7.6, 7.9, 7.9]\n",
    "# 19-x(lr=1e-5, start: 7.9): [7.4, 7.7, 7.5, 7.1, 7.7, 7.6, 7.5]\n",
    "# 10-x(lr=1e-5, start: 9.4): [8.2, 7.3, 7.9, 7.5, 7.0, 7.3, 7.3]\n",
    "fids_tr31b = [40.3, 54.2, 19.0, 16.3]\n",
    "# All: [40.3, 32.4, 35.9, 21.7, 54.2, 21.2, 18.2, 19.0, 14.9, 16.3, 22.1, 20.0]\n",
    "fids_tr32 = [22.5, 9.7, 11.0, 8.9]\n",
    "# All: [22.5, 16.6, 14.1, 12.9, 9.7, 12.1, 9.5, 11.0, 8.2, 8.9, 14.0, 9.3, 9.0, 10.9, 15.8]\n",
    "# 10-x(lr=5e-5): [8.45, 6.99, 7.80, 8.26, 13.35, 8.66, 7.86, 8.28, 7.63, 8.15, 7.34]\n",
    "# Alllr=1e-3: [20.0, 15.1, 13.0, 13.1, 13.8]\n",
    "fids_tr32b = [24.7, 11.7, 9.7, 14.5]\n",
    "# All: [24.7, 19.7, 15.3, 13.0, 11.7, 12.2, 10.3, 9.7, 11.0, 14.5]\n",
    "fids_tr32c = [23.7, 13.7, 13.0, 12.6]\n",
    "# All: [23.7, 15.3, 15.4, 12.8, 13.7, 11.3, 12.7, 13.0, 14.8, 12.6]\n",
    "fids_tr32d = [29.0, 12.5, 11.0, 11.0]\n",
    "# All: [25.1, 17.7, 15.6, 14.2, 12.5, 11.6, 11.8, 11.0, 9.9, 11.0, 10.7, 9.8, 9.7, 10.0, 10.9, 11.4, 10.6, 10.6]\n",
    "fids_tr33 = [21.7, 11.3, 10.1, 9.1]\n",
    "# All: [21.7, 14.9, 12.1, 12.1, 11.3, 9.6, 11.7, 10.1, 9.8, 9.1, 10.8, 9.8, 10.3, 49.1, 19.9]\n",
    "fids_tr33b = [21.7, 9.9, 11.9, 21.6]\n",
    "# All: [21.7, 13.5, 12.8, 12.0, 9.9, 10.2, 9.7, 11.9, 10.2, 21.6, 9.6, 10.3, 8.3, 12.9, 10.4, 11.4, 14.5, 11.3, 9.9, 10.6]\n",
    "fids_tr33c = [22.8, 9.6, 8.5, 9.7]\n",
    "# All:  [22.8, 15.3, 12.9, 13.3, 9.6, 11.3, 10.0, 8.5, 9.9, 9.7, 10.9, 9.3, 8.6, 11.4, 8.2, 11.3, 35.7, 13.3, 10.4, 10.5]\n",
    "# 16-20(lr=1e-4, start:8.2): [8.3, 8.8, 8.5, 8.6, 50.6]\n",
    "# 9-12(lr=1e-4, start:8.5): [9.4, 8.1, 9.6, 11.9]\n",
    "# 11-15(lr=5e-5, start:8.1): [8.3, 8.9, 8.2, 8.4, 8.3]\n",
    "# tr34: BAD\n",
    "fids_tr34b = [46.6, 27.7, 20.8, 20.2]\n",
    "# All: [46.6, 36.1, 28.7, 27.7, 27.7, 25.9, 24.3, 20.8, 20.6, 20.2]\n",
    "fids_tr34c = [35.0, 17.5, 16.1, 15.3]\n",
    "# 5-10: [17.5, 19.1, 16.7, 16.1, 16.7, 15.3]\n",
    "# tr34d: BAD\n",
    "fids_tr34e = [50.3, 23.4]\n",
    "# All: [50.3, 32.5, 24.2, 21.4, 23.4]\n",
    "fids_tr34f = [41.2, 17.6, ]\n",
    "# All: [41.2, 27.8, 21.6, 19.8, 17.6, 17.7, 14.4, 16.2]\n",
    "fids_tr34g = [35.6, 17.1, 14.7, 15.0]\n",
    "# All: [44.5, 25.0, 19.6, 15.9, 17.1, 11.9, 13.6, 14.7, 12.1, 15.0]\n",
    "fids_tr34h = [55.5, 16.3, 17.8, 18.0]\n",
    "# All: [55.5, 34.4, 25.6, 20.9, 16.3, 18.2, 16.6, 17.8, 17.4, 18.0, 16.1, 14.0, 15.7, 16.8, 15.3]\n",
    "fids_tr34i = [148.4, 28.3, 22.2, 22.2]\n",
    "# All: [148.4, 95.9, 52.9, 38.9, 28.3, 28.1, 28.0, 22.2, 21.3, 22.2]\n",
    "fids_tr35 = [34.0, 14.1, 9.7, 9.3]\n",
    "# All: [34.0, 19.4, 17.0, 14.3, 14.1, 11.8, 11.8, 9.7, 9.5, 9.3, 10.6, 10.3, 9.8, 9.3, 8.7]\n",
    "fids_tr35b = [26.5, 10.9, 10.0, 8.5]\n",
    "# All: [26.5, 16.8, 14.2, 10.4, 10.9, 10.0, 10.9, 10.0, 9.6, 8.5, 8.0, 8.2, 8.2, 8.0, 8.1, 7.1, 7.2, 7.6, 7.3, 7.6, 7.3, 7.1, 7.2]\n",
    "fids_tr35c = [24.9, 9.7]\n",
    "# All: [24.9, 19.1, 14.3, 13.2, 9.7, 10.4]\n",
    "\n",
    "\n",
    "fids_tr36 = [59.5, 18.6, 14.3, 12.0]\n",
    "# All: [59.5, 35.2, 30.3, 20.1, 18.6, 16.6, 13.6, 14.3, 12.2, 12.0]\n",
    "fids_tr36b = [46.0, 14.3, 10.9, 9.0]\n",
    "# All: [46.0, 26.6, 22.1, 15.7, 14.3, 12.3, 12.1, 10.9, 12.1, 9.0, 9.2, 10.9, 9.8, 8.7, 8.9, 8.7, 7.3, 9.3, 8.0, 7.1, 8.1, 7.6, 7.3]\n",
    "\n",
    "fids_tr37_skip_bias_true_no_act = [66.0, 27.1, 22.9, 20.5]\n",
    "# All: [66.0, 50.5, 36.6, 32.1, 27.1, 25.6, 23.8, 22.9, 24.4, 20.5]\n",
    "fids_tr37_skip_no_act = [58.7, 24.8, 15.1, 17.0]\n",
    "# All: [58.7, 35.6, 27.3, 25.2, 24.8, 17.3, 16.4, 15.1, 16.0, 17.0]\n",
    "fids_tr37a = [30.3, 13.6, 9.8, 11.4]\n",
    "# All: [30.3, 19.3, 16.1, 13.8, 13.6, 12.3, 10.0, 9.8, 49.8, 11.4, 9.8, 12.8]\n",
    "fids_tr37a2 = [26.4, 11.4, 9.9, 10.5]\n",
    "# All: [26.4, 18.8, 14.8, 10.6, 11.4, 10.0, 11.5, 9.9, 10.5, 10.5, 9.7, 9.5, 9.2, 9.7, 10.9]\n",
    "fids_tr37b = [39.6, 20.9, 16.1, 14.7]\n",
    "# All: [39.6, 24.1, 18.8, 17.9, 20.9, 19.4, 15.5, 16.1, 13.9, 14.7]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.lineplot(epochs, fids_tr1, label='tr1')\n",
    "sns.lineplot(epochs, fids_tr2, label='tr2')\n",
    "sns.lineplot(epochs, fids_tr3, label='tr3')\n",
    "sns.lineplot(epochs, fids_tr4, label='tr4')\n",
    "sns.lineplot(epochs, fids_tr5, label='tr5')\n",
    "sns.lineplot(epochs, fids_tr5b, label='tr5b')\n",
    "sns.lineplot(epochs, fids_tr6, label='tr6')\n",
    "sns.lineplot(epochs, fids_tr7, label='tr7')\n",
    "sns.lineplot(epochs, fids_tr8, label='tr8')\n",
    "sns.lineplot(epochs, fids_tr9, label='tr9')\n",
    "sns.lineplot(epochs, fids_tr10, label='tr10')\n",
    "ax = sns.lineplot(epochs, fids_tr11, label='tr11')\n",
    "ax.set_xlabel('Number of epochs')\n",
    "ax.set_ylabel('FID')\n",
    "#plt.legend(title='...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
